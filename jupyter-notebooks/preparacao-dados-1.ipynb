{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "republican-victorian",
   "metadata": {},
   "source": [
    "# Pulmonary Chest X-Ray Abnormalities\n",
    "\n",
    "## Dataset Kaggle\n",
    "***\n",
    "- [Pulmonary Chest X-Ray Abnormalities](https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities)\n",
    "\n",
    "\n",
    "## Contexto do problema\n",
    "***\n",
    "> A tuberculose é uma doença que afeta muitas pessoas nos países em desenvolvimento. Embora o tratamento seja possível, ela requer um diagnóstico preciso primeiro. Nos projetos de países, há em muitos casos máquinas de raio-X disponíveis (por meio de projetos de baixo custo e doações), mas muitas vezes falta a experiência radiológica para avaliar com precisão as imagens. Um algoritmo que pudesse realizar essa tarefa de forma rápida e barata poderia melhorar drasticamente a capacidade de diagnosticar e, em última análise, tratar a doença.  \n",
    "***\n",
    "> Em países mais desenvolvidos, a radiografia de raio-X é frequentemente usada para rastrear recém-chegados e determinar a elegibilidade para uma autorização de trabalho. A tarefa de examinar manualmente as imagens é demorada e um algoritmo pode aumentar a eficiência, melhorar o desempenho e, por fim, reduzir o custo dessa triagem.  \n",
    "***\n",
    "> Este conjunto de dados contém mais de 500 exames de raios-x com rótulos clínicos coletados por radiologistas.  \n",
    "\n",
    "### Dataset 1: Montgomery County X-ray Set\n",
    "***\n",
    "As imagens de raios-X neste conjunto de dados foram adquiridas do programa de controle da tuberculose do Departamento de Saúde e Serviços Humanos do Condado de Montgomery, MD, EUA. Esse conjunto de dados contém 138 radiografias póstero-anterior, das quais 80 são radiografias normais e 58 são anormais com manifestações de tuberculose. Todas as imagens são desidentificadas e disponíveis no formato DICOM (Digital Imaging and Communications in Medicine). O conjunto cobre uma ampla gama de anormalidades, incluindo efusões e padrões miliares. O conjunto de dados inclui leituras de radiologia disponíveis como um arquivo de texto (preservando a identidade dos pacientes).\n",
    "\n",
    "### Dataset 2: China Set - The Shenzhen set - Chest X-ray Database\n",
    "***\n",
    "O banco de dados de imagem digital padrão para tuberculose foi criado pela Biblioteca Nacional de Medicina, Maryland, EUA, em colaboração com o Hospital Popular de Shenzhen No.3, Faculdade de Medicina de Guangdong, Shenzhen, China. As radiografias de tórax são de clínicas ambulatoriais e foram capturadas como parte da rotina diária usando os sistemas Philips DR Digital Diagnose. O conjunto de dados contém 336 casos com manifestação de tuberculose e 326 casos normais.\n",
    "\n",
    "### Referências\n",
    "- Jaeger S, Candemir S, Antani S, Wáng YX, Lu PX, Thoma G. **Two public chest X-ray datasets for computer-aided screening of pulmonary diseases**. Quant Imaging Med Surg. 2014;4(6):475-477. doi:10.3978/j.issn.2223-4292.2014.11.20\n",
    "- Jaeger S, Karargyris A, Candemir S, Folio L, Siegelman J, Callaghan F, Xue Z, Palaniappan K, Singh RK, Antani S, Thoma G, Wang YX, Lu PX, McDonald CJ. **Automatic tuberculosis screening using chest radiographs**. IEEE Trans Med Imaging. 2014 Feb;33(2):233-45. doi: 10.1109/TMI.2013.2284099. PMID: 24108713\n",
    "- Candemir S, Jaeger S, Palaniappan K, Musco JP, Singh RK, Xue Z, Karargyris A, Antani S, Thoma G, McDonald CJ. **Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration**. IEEE Trans Med Imaging. 2014 Feb;33(2):577-90. doi: 10.1109/TMI.2013.2290491. PMID: 24239990"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-expression",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "grave-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-universe",
   "metadata": {},
   "source": [
    "## Indexando todas as imagens disponíveis no dataset\n",
    "***\n",
    "- `glob`: encontra nomes de arquivos usando as regras usadas pelo shell Unix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "mineral-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coletando o caminho dos arquivos dos dados do hospital montgomery\n",
    "filelist_montgomery = glob.glob('../datasets/archive/Montgomery/MontgomerySet/CXR_png/*.png')\n",
    "# coletando o caminho dos arquivos dos dados do hospital shenzen\n",
    "filelist_shenzen = glob.glob('../datasets/archive/ChinaSet_AllFiles/ChinaSet_AllFiles/CXR_png/*.png')\n",
    "# unindo o caminho dos arquivos dos hospitais montgomery e shenzen\n",
    "filelist = filelist_montgomery + filelist_shenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "italian-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de imagens: 800\n"
     ]
    }
   ],
   "source": [
    "# quantidade de imagens disponíveis no dataset\n",
    "print('quantidade de imagens:', str(len(filelist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-oriental",
   "metadata": {},
   "source": [
    "## Extraindo os rótulos das imagens\n",
    "***\n",
    "- `regex`: módulo de expressão regular para encontrar cadeias de caracteres.\n",
    "- `tqdm`: barra de carregamento gráfica para estruturas de repetição.\n",
    "\n",
    "#### Rótulos\n",
    "- `[0]` caso normal;\n",
    "- `[1]` caso anormal;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "military-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(file_list):\n",
    "    \n",
    "    # inicializando uma lista vazia\n",
    "    labels = []\n",
    "    \n",
    "    # iterando na lista de arquivos\n",
    "    for file in tqdm(file_list):\n",
    "        # detectando as classes presentes no nome da imagem\n",
    "        current_label = re.findall('[0-9]{4}_(.+?).png', file)\n",
    "        # adicionando a lista de rótulos as classes correspondentes a cada uma das imagens\n",
    "        labels.append(current_label[0])\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "periodic-angle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 6108.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# extraindo os rótulos\n",
    "labels = extract_label(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "difficult-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de rótulos: 800\n"
     ]
    }
   ],
   "source": [
    "# visualizando a quantidade de rótulos\n",
    "print('quantidade de rótulos:', str(len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-bicycle",
   "metadata": {},
   "source": [
    "## Criando um dataframe\n",
    "***\n",
    "- `pandas`: ferramenta de análise e manipulação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "willing-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataframe com os caminhos das imagens\n",
    "full_data = pd.DataFrame(filelist, columns = ['filepath'])\n",
    "# adicionando os rótulos em cada imagem\n",
    "full_data['target'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "returning-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_type = {'target': 'float32'}\n",
    "full_data = full_data.astype(dict_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-wings",
   "metadata": {},
   "source": [
    "## Dados [Treinamento - Validação - Teste]\n",
    "***\n",
    "- `scikit-learn:` biblioteca de aprendizado de máquina de código aberto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dramatic-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de treinamento e de teste\n",
    "train_df, test_df = train_test_split(full_data, stratify = full_data['target'],\n",
    "                                     test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "brazilian-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de validação dos dados de treinamento\n",
    "train_df, validation_df = train_test_split(train_df, stratify = train_df['target'],\n",
    "                                           test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "adequate-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de imagens de treinamento: 512\n",
      "quantidade de rótulos de treinamento: 512\n",
      "quantidade de imagens de teste: 160\n",
      "quantidade de rótulos de teste: 160\n",
      "quantidade de imagens de validação: 128\n",
      "quantidade de rótulos de validação: 128\n"
     ]
    }
   ],
   "source": [
    "# visualizando a quantidade de dados\n",
    "print('quantidade de imagens de treinamento:', len(train_df['filepath']))\n",
    "print('quantidade de rótulos de treinamento:', len(train_df['target']))\n",
    "print('quantidade de imagens de teste:', len(test_df['filepath']))\n",
    "print('quantidade de rótulos de teste:', len(test_df['target']))\n",
    "print('quantidade de imagens de validação:', len(validation_df['filepath']))\n",
    "print('quantidade de rótulos de validação:', len(validation_df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "known-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 validated image filenames.\n",
      "Found 128 validated image filenames.\n",
      "Found 160 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
    "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True,\n",
    "                                     rotation_range = 20, zoom_range = 0.2)\n",
    "\n",
    "# criando o gerador de imagens de treinamento \n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "                                                      dataframe = train_df,\n",
    "                                                      directory = '',\n",
    "                                                      x_col = 'filepath',\n",
    "                                                      y_col = 'target',\n",
    "                                                      batch_size = 32,\n",
    "                                                      seed = 42,\n",
    "                                                      shuffle = True,\n",
    "                                                      class_mode = 'raw',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      target_size = (256, 256))\n",
    "# criando o gerador de imagens de validação \n",
    "valid_generator = image_generator.flow_from_dataframe(\n",
    "                                                      dataframe = validation_df,\n",
    "                                                      directory = '.', \n",
    "                                                      x_col = 'filepath',\n",
    "                                                      y_col = 'target',\n",
    "                                                      batch_size = 32,\n",
    "                                                      seed = 42,\n",
    "                                                      shuffle = True,\n",
    "                                                      class_mode = 'raw',\n",
    "                                                      target_size = (256, 256))\n",
    "\n",
    "# normalizando as imagens de teste \n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "                                                  dataframe = test_df, \n",
    "                                                  directory = '.',\n",
    "                                                  x_col = 'filepath',\n",
    "                                                  y_col = 'target',\n",
    "                                                  batch_size = 32,\n",
    "                                                  seed = 42,\n",
    "                                                  shuffle = True,\n",
    "                                                  class_mode = 'raw',\n",
    "                                                  target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-blood",
   "metadata": {},
   "source": [
    "## Definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "happy-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o local do arquivo em que os pesos devem ser salvos \n",
    "filepath = \"transferlearning_weights.hdf5\" \n",
    "# definindo um callback de checkpoint para salvar os pesos durante o treinamento  \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "rural-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo um callback de redução da taxa de aprendizado caso a rede entre em um platô  \n",
    "lr_reduce = ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, min_delta = 1e-5, patience = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "northern-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo uma lista de callbacks\n",
    "callbacks = [checkpoint, lr_reduce] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "guilty-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferência de aprendizado\n",
    "conv_base = VGG19(weights = 'imagenet', include_top = False, input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "flexible-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualizando o a arquitetura VGG19 utilizada \n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "normal-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo inicialmente toda rede como treinável \n",
    "conv_base.trainable = True\n",
    "# criando uma flag \n",
    "set_trainable = False\n",
    "\n",
    "# iterando entre as camadas da rede convolucional VGG19 \n",
    "for layer in conv_base.layers:\n",
    "    # caso estiver na última camada... \n",
    "    if layer.name == 'block5_conv1':\n",
    "        # configure-a como treinável \n",
    "        set_trainable = True\n",
    "    \n",
    "    # caso a flag for verdadeira (na última camada)...\n",
    "    if set_trainable:\n",
    "        # mantenha a camada treinável \n",
    "        layer.trainable = True\n",
    "    # caso a flag seja falsa (demais camadas)... \n",
    "    else:\n",
    "        # mantenha as características aprendidas pelas camadas (não treináveis) \n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "reliable-america",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# observando a arquitetura da rede após o refinamento\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aware-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo um modelo sequencial de rede neural \n",
    "model = models.Sequential()\n",
    "# adicionando toda a arquitetura da VGG19 após o refinamento \n",
    "model.add(conv_base)\n",
    "# adicionando uma camada de pooling (método do maior píxel) \n",
    "model.add(layers.MaxPooling2D())\n",
    "# aplicando uma camada de normalização para otimizar a rede \n",
    "model.add(layers.BatchNormalization())\n",
    "# aplicando uma camada de achatamento para conectar as camadas de convolução a uma rede neural densa \n",
    "model.add(layers.Flatten())\n",
    "# definindo uma camada densa com 128 neurônios e uma função de ativação relu\n",
    "model.add(layers.Dense(units = 128, activation = tf.nn.relu))\n",
    "# aplicando uma camada de normalização na rede neural densa (zera 20% dos neurônios da camada anterior)\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "# aplicando uma camada de saída com 15 unidades e uma função de ativação softmax \n",
    "model.add(layers.Dense(units = 2, activation = tf.nn.softmax)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "possible-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 8, 8, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 21,075,394\n",
      "Trainable params: 10,489,218\n",
      "Non-trainable params: 10,586,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualizando a nova arquitetura definida baseada em transferência de aprendizado\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "closed-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilando o modelo\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-carry",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 468s 28s/step - loss: 1.5112 - acc: 0.4831 - val_loss: 7.0906 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50781, saving model to transferlearning_weights.hdf5\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 442s 27s/step - loss: 0.6969 - acc: 0.5194 - val_loss: 3.0523 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50781\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 416s 26s/step - loss: 0.6932 - acc: 0.4954 - val_loss: 1.2784 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.50781\n",
      "Epoch 4/50\n",
      " 3/16 [====>.........................] - ETA: 6:11 - loss: 0.6932 - acc: 0.4583"
     ]
    }
   ],
   "source": [
    "# treinando a rede \n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = 512 // 32, \n",
    "                              validation_data = valid_generator,\n",
    "                              validation_steps = 128 // 32,\n",
    "                              callbacks = callbacks, epochs = 50, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
