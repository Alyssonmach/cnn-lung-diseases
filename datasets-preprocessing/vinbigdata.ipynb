{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patent-bracelet",
   "metadata": {},
   "source": [
    "# Conjunto de Dados 3: *VinBigData Dataset*\n",
    "***\n",
    "* Disponível em: <https://www.kaggle.com/awsaf49/vinbigdata-original-image-dataset>. Acesso em 24 fev. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-feature",
   "metadata": {},
   "source": [
    "### Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "placed-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-exhibit",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-danger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de imagens disponíveis: 15000\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('../0-datasets/vinbigdata/arquivos-descompactados/vinbigdata/train.csv')\n",
    "path = '../0-datasets/vinbigdata/arquivos-descompactados/vinbigdata/train/'\n",
    "dataframe['image_path'] = path + dataframe.image_id + '.jpg'\n",
    "\n",
    "print('total de imagens disponíveis:', str(len(set(dataframe['image_path']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "public-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No finding            31818\n",
       "Aortic enlargement     7162\n",
       "Cardiomegaly           5427\n",
       "Pleural thickening     4842\n",
       "Pulmonary fibrosis     4655\n",
       "Nodule/Mass            2580\n",
       "Lung Opacity           2483\n",
       "Pleural effusion       2476\n",
       "Other lesion           2203\n",
       "Infiltration           1247\n",
       "ILD                    1000\n",
       "Calcification           960\n",
       "Consolidation           556\n",
       "Atelectasis             279\n",
       "Pneumothorax            226\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "other-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de dados após a filtração: 13948\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataframe[dataframe.class_name != 'Aortic enlargement']\n",
    "dataframe = dataframe[dataframe.class_name != 'Cardiomegaly']\n",
    "dataframe = dataframe[dataframe.class_name != 'Other lesion']\n",
    "dataframe = dataframe[dataframe.class_name != 'Consolidation']\n",
    "\n",
    "normal_cases = dataframe[(dataframe.class_id == 14) & (dataframe.class_name == 'No finding')]\n",
    "abnormal_cases = dataframe[(dataframe.class_id != 14) & (dataframe.class_name != 'No finding')]\n",
    "lenght_images = len(set(normal_cases['image_path'])) + len(set(abnormal_cases['image_path']))\n",
    "print('total de dados após a filtração: {}'.format(lenght_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de dados rotulados como normais: 10606\n",
      "quantidade de dados rotulados como anormais: 3342\n"
     ]
    }
   ],
   "source": [
    "normal_data = normal_cases[['image_path', 'class_name']].drop_duplicates(subset = 'image_path')\n",
    "abnormal_data = abnormal_cases[['image_path', 'class_name']].drop_duplicates(subset = 'image_path')\n",
    "normal_data['target'] = 'normal'\n",
    "abnormal_data['target'] = 'abnormal'\n",
    "\n",
    "print('quantidade de dados rotulados como normais:', len(normal_data))\n",
    "print('quantidade de dados rotulados como anormais:', len(abnormal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moderate-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de dados rotulados como normais: 3287\n",
      "quantidade de dados rotulados como anormais: 3342\n"
     ]
    }
   ],
   "source": [
    "normal, _ = train_test_split(normal_data, test_size = 0.69, random_state = 42)\n",
    "\n",
    "print('quantidade de dados rotulados como normais:', len(normal))\n",
    "print('quantidade de dados rotulados como anormais:', len(abnormal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fatal-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de imagens de treinamento: 4242\n",
      "quantidade de rótulos de treinamento: 4242\n",
      "quantidade de imagens de teste: 1326\n",
      "quantidade de rótulos de teste: 1326\n",
      "quantidade de imagens de validação: 1061\n",
      "quantidade de rótulos de validação: 1061\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([normal, abnormal_data])\n",
    "train_df, test_df = train_test_split(full_data, stratify = full_data['target'], test_size = 0.2, random_state = 42)\n",
    "train_df, validation_df = train_test_split(train_df, stratify = train_df['target'], test_size = 0.2, random_state = 42)\n",
    "\n",
    "print('quantidade de imagens de treinamento:', len(train_df['image_path']))\n",
    "print('quantidade de rótulos de treinamento:', len(train_df['target']))\n",
    "print('quantidade de imagens de teste:', len(test_df['image_path']))\n",
    "print('quantidade de rótulos de teste:', len(test_df['target']))\n",
    "print('quantidade de imagens de validação:', len(validation_df['image_path']))\n",
    "print('quantidade de rótulos de validação:', len(validation_df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764b97c8-2b59-4c04-966d-58f388e44f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_df['class_name']), train_df['class_name'])\n",
    "class_weight = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], \n",
    "                3: class_weights[3], 4: class_weights[4], 5: class_weights[5],\n",
    "                6: class_weights[6], 7: class_weights[7], 8: class_weights[8],\n",
    "                9: class_weights[9], 10: class_weights[10]}\n",
    "                \n",
    "train_df.to_csv('train_df.csv')\n",
    "validation_df.to_csv('validation_df.csv')\n",
    "test_df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-trance",
   "metadata": {},
   "source": [
    "### Gerador de dados para a rede pelo Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "skilled-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4242 validated image filenames belonging to 2 classes.\n",
      "Found 1061 validated image filenames belonging to 2 classes.\n",
      "Found 1326 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True,\n",
    "                                     rotation_range = 10, zoom_range = 0.2)\n",
    "\n",
    "train_generator = image_generator.flow_from_dataframe(dataframe = train_df, directory = '', x_col = 'image_path',\n",
    "                                                      y_col = 'target', batch_size = 32, seed = 42,\n",
    "                                                      shuffle = True, class_mode = 'categorical',\n",
    "                                                      target_size = (256, 256))\n",
    " \n",
    "valid_generator = image_generator.flow_from_dataframe(dataframe = validation_df, directory = '.', x_col = 'image_path', \n",
    "                                                      y_col = 'target', batch_size = 32, seed = 42,\n",
    "                                                      shuffle = True, class_mode = 'categorical',\n",
    "                                                      target_size = (256, 256))\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe = test_df, directory = '.', x_col = 'image_path',\n",
    "                                                  y_col = 'target', batch_size = 32, seed = 42,\n",
    "                                                  shuffle = True, class_mode = 'categorical',\n",
    "                                                  target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd88c37a-b18f-4d34-92ee-03baa4f2cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abnormal': 0, 'normal': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
