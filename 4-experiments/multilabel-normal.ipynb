{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "experimento2-dataset4.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demanding-medication"
      },
      "source": [
        "# Experimento 2\n",
        "***\n",
        "- Conjunto de Dados: VinBigData\n",
        "- Analisando o efeito do valor médio de duas redes treinadas."
      ],
      "id": "demanding-medication"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laughing-kazakhstan"
      },
      "source": [
        "### Importação dos pacotes"
      ],
      "id": "laughing-kazakhstan"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-billion"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import urllib.request as url\n",
        "\n",
        "url.urlretrieve('https://raw.githubusercontent.com/Alyssonmach/cnn-lung-diseases/main/assets/lung_segmentation.py', \n",
        "                'lung_segmentation.py')\n",
        "from lung_segmentation import segmentation\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "applicable-billion",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca8k892QZQ1y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import albumentations as A\n",
        "from lungs_segmentation.pre_trained_models import create_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from lungs_segmentation.pre_trained_models import create_model\n",
        "import lungs_segmentation.inference as inference\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "model_seg = create_model(\"resnet34\", )\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#model_seg = model_seg.to(device)\n",
        "\n",
        "def segmentation(image, path = 'image.png'):\n",
        "\n",
        "  image = tf.keras.preprocessing.image.array_to_img(image)\n",
        "  tf.keras.preprocessing.image.save_img(path, image)\n",
        "  image, mask = inference.inference(model_seg, path, 0.2)\n",
        "  os.remove(path)\n",
        "  for values_i in range(0, len(mask[0])):\n",
        "    for values_j in range(0, len(mask[0])):\n",
        "      if (mask[0, values_i, values_j] + mask[1, values_i, values_j]) == 0:\n",
        "        image[values_i, values_j, 0] = 0\n",
        "        image[values_i, values_j, 1] = 0\n",
        "        image[values_i, values_j, 2] = 0\n",
        "  \n",
        "  return image"
      ],
      "id": "Ca8k892QZQ1y",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worst-fisher"
      },
      "source": [
        "### Pré-processamento nos dados"
      ],
      "id": "worst-fisher"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "regulation-costume"
      },
      "source": [
        "# lendo os dados de um arquivo csv\n",
        "dataframe = pd.read_csv('/content/drive/MyDrive/vinbigdata/train.csv')\n",
        "# criando uma coluna com os caminhos relativos as imagens\n",
        "dataframe['image_path'] = '/content/drive/MyDrive/vinbigdata/train/' + dataframe.image_id + '.jpg'"
      ],
      "id": "regulation-costume",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "necessary-medication",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f0ddaf-c7e6-4a16-9315-735cbb74163d"
      },
      "source": [
        "print('total de imagens disponíveis:', str(len(set(dataframe['image_path']))))"
      ],
      "id": "necessary-medication",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total de imagens disponíveis: 15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "widespread-enclosure",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ed60e4-df63-4901-a67f-2407d8b9dfe1"
      },
      "source": [
        "# visualizando os casos disponíveis\n",
        "dataframe['class_name'].value_counts()"
      ],
      "id": "widespread-enclosure",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No finding            31818\n",
              "Aortic enlargement     7162\n",
              "Cardiomegaly           5427\n",
              "Pleural thickening     4842\n",
              "Pulmonary fibrosis     4655\n",
              "Nodule/Mass            2580\n",
              "Lung Opacity           2483\n",
              "Pleural effusion       2476\n",
              "Other lesion           2203\n",
              "Infiltration           1247\n",
              "ILD                    1000\n",
              "Calcification           960\n",
              "Consolidation           556\n",
              "Atelectasis             279\n",
              "Pneumothorax            226\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "informal-ottawa"
      },
      "source": [
        "# removendo os casos não relativos a distúrbios pulmonares\n",
        "dataframe = dataframe[dataframe.class_name != 'Aortic enlargement']\n",
        "dataframe = dataframe[dataframe.class_name != 'Cardiomegaly']\n",
        "dataframe = dataframe[dataframe.class_name != 'Other lesion']\n",
        "dataframe = dataframe[dataframe.class_name != 'Consolidation']"
      ],
      "id": "informal-ottawa",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plastic-master",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe2aabf-b488-4ee1-8af1-fc584ba90680"
      },
      "source": [
        "# separando os casos rotulados como normais e anormais\n",
        "normal_cases = dataframe[(dataframe.class_id == 14) & (dataframe.class_name == 'No finding')]\n",
        "abnormal_cases = dataframe[(dataframe.class_id != 14) & (dataframe.class_name != 'No finding')]\n",
        "\n",
        "print('total de dados após a filtração:', str(len(set(normal_cases['image_path'])) + len(set(abnormal_cases['image_path']))))"
      ],
      "id": "plastic-master",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total de dados após a filtração: 13948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secure-alignment"
      },
      "source": [
        "# removendo as imagens repetidas\n",
        "normal_data = normal_cases[['image_path', 'class_name']].drop_duplicates(subset = 'image_path', )\n",
        "abnormal_data = abnormal_cases[['image_path', 'class_name']].drop_duplicates(subset = 'image_path', )\n",
        "\n",
        "# criando dataframes especifos com caminhos para as imagens e rótulos\n",
        "normal_data['target'] = 'normal'\n",
        "abnormal_data['target'] = 'abnormal'"
      ],
      "id": "secure-alignment",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sudden-platform",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec374a9-063c-45ba-f33e-1a1eb848cc19"
      },
      "source": [
        "print('quantidade de dados rotulados como normais:', len(normal_data))\n",
        "print('quantidade de dados rotulados como anormais:', len(abnormal_data))"
      ],
      "id": "sudden-platform",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de dados rotulados como normais: 10606\n",
            "quantidade de dados rotulados como anormais: 3342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prompt-embassy"
      },
      "source": [
        "# removendo 69% dos casos normais para balancear os dados\n",
        "normal, _ = train_test_split(normal_data, test_size = 0.69, random_state = 42)"
      ],
      "id": "prompt-embassy",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sitting-works",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155cdf03-7247-4d3f-c617-a3ff40116b66"
      },
      "source": [
        "print('quantidade de dados rotulados como normais:', len(normal))\n",
        "print('quantidade de dados rotulados como anormais:', len(abnormal_data))"
      ],
      "id": "sitting-works",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de dados rotulados como normais: 3287\n",
            "quantidade de dados rotulados como anormais: 3342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "funny-document"
      },
      "source": [
        "# concatenando os dataframes de casos normais e anormais\n",
        "full_data = pd.concat([normal, abnormal_data])"
      ],
      "id": "funny-document",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "golden-reading"
      },
      "source": [
        "# misturando todos os dados do dataframe e reiniciando os valores dos índices \n",
        "full_data = full_data.sample(frac = 1, axis = 0, random_state = 42).reset_index(drop=True)"
      ],
      "id": "golden-reading",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medium-brand"
      },
      "source": [
        "# separando os dados de treinamento e de teste\n",
        "train_df, test_df = train_test_split(full_data, stratify = full_data['target'],\n",
        "                                     test_size = 0.2, random_state = 42)"
      ],
      "id": "medium-brand",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extraordinary-retrieval"
      },
      "source": [
        "# separando os dados de validação dos dados de treinamento\n",
        "train_df, validation_df = train_test_split(train_df, stratify = train_df['target'],\n",
        "                                           test_size = 0.2, random_state = 42)"
      ],
      "id": "extraordinary-retrieval",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dependent-collins",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813d891d-7d5a-4299-9476-c31bfb4e2eb5"
      },
      "source": [
        "# visualizando a quantidade de dados\n",
        "print('quantidade de imagens de treinamento:', len(train_df['image_path']))\n",
        "print('quantidade de rótulos de treinamento:', len(train_df['target']))\n",
        "print('quantidade de imagens de teste:', len(test_df['image_path']))\n",
        "print('quantidade de rótulos de teste:', len(test_df['target']))\n",
        "print('quantidade de imagens de validação:', len(validation_df['image_path']))\n",
        "print('quantidade de rótulos de validação:', len(validation_df['target']))"
      ],
      "id": "dependent-collins",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de imagens de treinamento: 4242\n",
            "quantidade de rótulos de treinamento: 4242\n",
            "quantidade de imagens de teste: 1326\n",
            "quantidade de rótulos de teste: 1326\n",
            "quantidade de imagens de validação: 1061\n",
            "quantidade de rótulos de validação: 1061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUGdPMp1MnFy",
        "outputId": "2da48ab1-f1fc-4c2b-f714-af2f92c1bc4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de exemplos disponíveis nos dados de treinamento\n",
        "train_df['class_name'].value_counts()"
      ],
      "id": "BUGdPMp1MnFy",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No finding            2104\n",
              "Pleural thickening     586\n",
              "Pulmonary fibrosis     473\n",
              "Lung Opacity           297\n",
              "Pleural effusion       223\n",
              "Nodule/Mass            216\n",
              "Infiltration           108\n",
              "Calcification          104\n",
              "ILD                     90\n",
              "Atelectasis             24\n",
              "Pneumothorax            17\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15lrj6xgM2by",
        "outputId": "4e161174-b057-4380-989d-c4dead7be9df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de exemplos disponíveis nos dados de validação\n",
        "validation_df['class_name'].value_counts()"
      ],
      "id": "15lrj6xgM2by",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No finding            526\n",
              "Pleural thickening    143\n",
              "Pulmonary fibrosis    125\n",
              "Lung Opacity           71\n",
              "Nodule/Mass            65\n",
              "Pleural effusion       44\n",
              "ILD                    25\n",
              "Infiltration           23\n",
              "Calcification          23\n",
              "Atelectasis            11\n",
              "Pneumothorax            5\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmr4M8tgM630",
        "outputId": "58b721bf-5a40-41ee-953d-1e27d74792ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de exemplos disponíveis nos dados de teste\n",
        "test_df['class_name'].value_counts()"
      ],
      "id": "Tmr4M8tgM630",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No finding            657\n",
              "Pleural thickening    179\n",
              "Pulmonary fibrosis    148\n",
              "Lung Opacity           80\n",
              "Nodule/Mass            66\n",
              "Pleural effusion       65\n",
              "Calcification          40\n",
              "Infiltration           38\n",
              "ILD                    37\n",
              "Atelectasis            10\n",
              "Pneumothorax            6\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "requested-pakistan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae21fd0-c33f-4158-f433-7d23304d734a"
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(preprocessing_function = segmentation)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      directory = '',\n",
        "                                                      x_col = 'image_path',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      target_size = (512, 512))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df,\n",
        "                                                      directory = '.', \n",
        "                                                      x_col = 'image_path',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      target_size = (512, 512))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  directory = '.',\n",
        "                                                  x_col = 'image_path',\n",
        "                                                  y_col = 'target',\n",
        "                                                  batch_size = 32,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  target_size = (512, 512))"
      ],
      "id": "requested-pakistan",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4242 validated image filenames belonging to 2 classes.\n",
            "Found 1061 validated image filenames belonging to 2 classes.\n",
            "Found 1326 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAUyG95WjVy"
      },
      "source": [
        "### Preparando a rede neural convolucional"
      ],
      "id": "uzAUyG95WjVy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe4WsyWLWlqo",
        "outputId": "dd6088ec-e8b2-4ad1-a142-e58fb882762d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = MobileNetV2(input_shape = (512, 512, 3), include_top = False, weights = 'imagenet', \n",
        "                    classes = 2, classifier_activation = 'softmax')\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "x = tf.keras.layers.Dense(units = 512, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(units = 216, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = tf.keras.layers.Dense(units = 2, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs = model.input, outputs = x)"
      ],
      "id": "pe4WsyWLWlqo",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lu_vmNGXy1B"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"transferlearning_weights.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
      ],
      "id": "8lu_vmNGXy1B",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB-Mbi3QX3YK"
      },
      "source": [
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]"
      ],
      "id": "eB-Mbi3QX3YK",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd512vsWbQCx"
      },
      "source": [
        "for indices in range(0,10):\n",
        "  (x1, y1) = train_generator[indices]\n",
        "  if indices == 0:\n",
        "    x, y = x1, y1\n",
        "  x, y = np.concatenate([x, x1]), np.concatenate([y, y1])"
      ],
      "id": "Wd512vsWbQCx",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEkzFqnZbeI8"
      },
      "source": [
        "for indices in range(0,5):\n",
        "  (z1, w1) = valid_generator[indices]\n",
        "  if indices == 0:\n",
        "    z, w = z1, w1\n",
        "  z, w = np.concatenate([z, z1]), np.concatenate([w, w1])"
      ],
      "id": "fEkzFqnZbeI8",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnSLlHzNbUsh"
      },
      "source": [
        "for indices in range(0,5):\n",
        "  (a1, b1) = test_generator[indices]\n",
        "  if indices == 0:\n",
        "    a, b = a1, b1\n",
        "  a, b = np.concatenate([a, a1]), np.concatenate([b, b1])"
      ],
      "id": "QnSLlHzNbUsh",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INOBVe1vYR-n"
      },
      "source": [
        "# compilando a rede \n",
        "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.0001), loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "id": "INOBVe1vYR-n",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECumd3GBX7wC",
        "outputId": "ec088fc7-b431-484a-ac36-42a28a6793d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 4242 // 32, \n",
        "                              validation_data = valid_generator, validation_steps = 1061 // 32,\n",
        "                              callbacks = callbacks, epochs = 10)"
      ],
      "id": "ECumd3GBX7wC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 18/132 [===>..........................] - ETA: 1:32:17 - loss: 0.6371 - acc: 0.6454"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "compatible-fetish"
      },
      "source": [
        "### Preparando a rede neural convolucional"
      ],
      "id": "compatible-fetish"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-rotation"
      },
      "source": [
        "# baixando os pesos treinados da rede inception\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "id": "anonymous-rotation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compact-knife"
      },
      "source": [
        "# referenciando o local em que os pesos estão armazenados\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# carregando a arquitetura inception pré-treinada\n",
        "pre_trained_model = InceptionV3(input_shape = (512, 512, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "# carregando os pesos treinados com outros dados \n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# definindo as flags iniciais  \n",
        "pre_trained_model.trainable = True\n",
        "set_trainable = False\n",
        "\n",
        "# para a arquitetura inception, a rede será retreinada a partir da camada 'mixed8'\n",
        "for layer in pre_trained_model.layers:\n",
        "    if layer.name == 'mixed8':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# obtendo a última camada como sendo a nomeada por 'mixed7'\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output"
      ],
      "id": "compact-knife",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "double-sound"
      },
      "source": [
        "# definindo uma camada de achatamento\n",
        "x = layers.Flatten()(last_output)\n",
        "# conecatando a rede uma camada com 1024 neurônios e função de ativação relu\n",
        "x = layers.Dense(units = 1024, activation = 'relu')(x)     \n",
        "# conecatando a rede uma camada com 128 neurônios e função de ativação relu\n",
        "x = layers.Dense(units = 512, activation = 'relu')(x) \n",
        "# aplicando uma camada de dropout com uma taxa de 20% (normalização)\n",
        "x = layers.Dropout(rate = 0.2)(x)                  \n",
        "# adicionando uma camada de saída com um neurônio e uma função de ativação sigmoide\n",
        "x = layers.Dense  (units = 2, activation = 'softmax')(x)           \n",
        "\n",
        "# conecatando as camadas definidas acima com a arquitetura inception\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "# compilando a rede \n",
        "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.0001), loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "id": "double-sound",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "found-baker"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"transferlearning_weights.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
      ],
      "id": "found-baker",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forward-guide"
      },
      "source": [
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]"
      ],
      "id": "forward-guide",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vital-constitutional"
      },
      "source": [
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 4242 // 32, \n",
        "                              validation_data = valid_generator, validation_steps = 1061 // 32,\n",
        "                              callbacks = callbacks, epochs = 10)"
      ],
      "id": "vital-constitutional",
      "execution_count": null,
      "outputs": []
    }
  ]
}