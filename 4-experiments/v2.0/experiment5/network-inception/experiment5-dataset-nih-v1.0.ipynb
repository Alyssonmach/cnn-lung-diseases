{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment5-dataset-nih.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lltg8Aim2eBk"
      },
      "source": [
        "# Experimento 5\n",
        "***\n",
        "- Rede Inception\n",
        "- Conjunto de Dados: NIH\n",
        "- Analisando o treinamento de uma rede com multiclassificadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGc_sJwE2v7L"
      },
      "source": [
        "### Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VNdgNJh2nu_"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBlFN3uN250P"
      },
      "source": [
        "### Importação dos dados\n",
        "***\n",
        "- Todo o dataset foi pré-processado anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8L6EUve227_"
      },
      "source": [
        "# importando os dataframes dos dados de treinamento, validação e teste\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/train_df.csv', sep = ',', index_col=  0)\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/validation_df.csv', sep = ',', index_col=  0)\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test_df.csv' , sep = ',', index_col=  0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqKuqHF4DUa1"
      },
      "source": [
        "# tornando as classes na coluna 'labels' categórica\n",
        "train_df.loc[train_df.labels == 1, 'labels'] = 'abnormal'\n",
        "train_df.loc[train_df.labels == 0, 'labels'] = 'normal'\n",
        "\n",
        "validation_df.loc[validation_df.labels == 1, 'labels'] = 'abnormal'\n",
        "validation_df.loc[validation_df.labels == 0, 'labels'] = 'normal'\n",
        "\n",
        "test_df.loc[test_df.labels == 1, 'labels'] = 'abnormal'\n",
        "test_df.loc[test_df.labels == 0, 'labels'] = 'normal'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD0VanbMmn2K"
      },
      "source": [
        "# ajustando a quantidade de exemplos nos dados de treinamento relativo a radiográficas normais\n",
        "train_normal_cases = train_df[train_df.labels == 'normal']\n",
        "train_abnormal_cases = train_df[train_df.labels == 'abnormal']\n",
        "train_normal_cases, _ = train_test_split(train_normal_cases, test_size = 0.5, random_state = 42)\n",
        "train = np.concatenate((train_normal_cases, train_abnormal_cases))\n",
        "train_df = pd.DataFrame(train, columns = ['Image Index', 'finding_labels', 'labels'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a9uNHRrS4Uin",
        "outputId": "7478ab8d-354c-4e1d-fa07-47689c93d53b"
      },
      "source": [
        "# visualizando como é a organização do dataframe pré-processado\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>finding_labels</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/images-nih4/images/0002...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/images-nih3/images/0001...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/images-nih2/images/0000...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/images-nih2/images/0000...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/images-nih2/images/0001...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Image Index finding_labels  labels\n",
              "0  /content/drive/MyDrive/images-nih4/images/0002...     No Finding  normal\n",
              "1  /content/drive/MyDrive/images-nih3/images/0001...     No Finding  normal\n",
              "2  /content/drive/MyDrive/images-nih2/images/0000...     No Finding  normal\n",
              "3  /content/drive/MyDrive/images-nih2/images/0000...     No Finding  normal\n",
              "4  /content/drive/MyDrive/images-nih2/images/0001...     No Finding  normal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGd53xcdiiY",
        "outputId": "97025108-b3af-4f55-edf4-a5344c7a384e"
      },
      "source": [
        "# visualizando a quantidade de imagens disponíveis por classe\n",
        "train_df['finding_labels'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No Finding            27811\n",
              "Infiltration           8770\n",
              "Atelectasis            3902\n",
              "Effusion               3645\n",
              "Nodule                 2497\n",
              "Pneumothorax           2024\n",
              "Consolidation          1224\n",
              "Pleural_Thickening     1028\n",
              "Emphysema               818\n",
              "Fibrosis                671\n",
              "Edema                   578\n",
              "Pneumonia               295\n",
              "Name: finding_labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eidsDkVFdwde"
      },
      "source": [
        "# organizando um dicionário para realizar o balanceamento nos dados das classes\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_df['finding_labels']),\n",
        "                                                  train_df['finding_labels'])\n",
        "class_weight = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2], \n",
        "                3: class_weights[3], 4: class_weights[4], 5: class_weights[5],\n",
        "                6: class_weights[6], 7: class_weights[7], 8: class_weights[8],\n",
        "                9: class_weights[9], 10: class_weights[10], 11: class_weights[11]}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nikcd9Fj4tpv",
        "outputId": "c1f64a09-3dfe-4da1-e419-23d263bbc2b4"
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(rescale = 1./255., rotation_range = 10, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 256,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = test_datagen.flow_from_dataframe(\n",
        "                                                    dataframe = validation_df,\n",
        "                                                    x_col = 'Image Index',\n",
        "                                                    y_col = 'finding_labels',\n",
        "                                                    batch_size = 128,\n",
        "                                                    seed = 42,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (256, 256))\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  x_col = 'Image Index',\n",
        "                                                  y_col = 'finding_labels',\n",
        "                                                  batch_size = 128,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  target_size = (256, 256))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 53259 validated image filenames belonging to 12 classes.\n",
            "Found 4268 validated image filenames belonging to 12 classes.\n",
            "Found 2640 validated image filenames belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s37H75lFDbZ_",
        "outputId": "9943f4f9-d445-477c-f863-5eeb83b5a9d9"
      },
      "source": [
        "# visualizando a ordem numérica das classes nos dados de treinamento\n",
        "train_generator.class_indices"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Atelectasis': 0,\n",
              " 'Consolidation': 1,\n",
              " 'Edema': 2,\n",
              " 'Effusion': 3,\n",
              " 'Emphysema': 4,\n",
              " 'Fibrosis': 5,\n",
              " 'Infiltration': 6,\n",
              " 'No Finding': 7,\n",
              " 'Nodule': 8,\n",
              " 'Pleural_Thickening': 9,\n",
              " 'Pneumonia': 10,\n",
              " 'Pneumothorax': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy6pLh4c5Gk4"
      },
      "source": [
        "### Preparando a rede neural convolucional "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp0U2-Ut5Xvq",
        "outputId": "5078cba7-1a1f-4e47-e4a2-7ef32fd0dc85"
      },
      "source": [
        "# baixando os pesos treinados da rede inception\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-14 23:06:50--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   106MB/s    in 0.8s    \n",
            "\n",
            "2021-04-14 23:06:51 (106 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxH8IPA15bIi"
      },
      "source": [
        "# referenciando o local em que os pesos estão armazenados\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# carregando a arquitetura inception pré-treinada\n",
        "pre_trained_model = InceptionV3(input_shape = (256, 256, 3), include_top = False, weights = None)\n",
        "\n",
        "# carregando os pesos treinados com outros dados \n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# definindo as flags iniciais  \n",
        "pre_trained_model.trainable = True\n",
        "set_trainable = False\n",
        "\n",
        "# para a arquitetura inception, a rede será retreinada a partir da camada 'mixed6'\n",
        "for layer in pre_trained_model.layers:\n",
        "    if layer.name == 'mixed6':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# obtendo a última camada como sendo a nomeada por 'mixed7'\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXwzaXiT58Oi"
      },
      "source": [
        "# definindo uma camada de achatamento\n",
        "x = layers.Flatten()(last_output)\n",
        "# conecatando a rede uma camada com 1024 neurônios e função de ativação relu\n",
        "x = layers.Dense(units = 1024, activation = tf.nn.relu)(x)     \n",
        "# conecatando a rede uma camada com 128 neurônios e função de ativação relu\n",
        "x = layers.Dense(units = 512, activation = tf.nn.relu)(x) \n",
        "# aplicando uma camada de dropout com uma taxa de 20% (normalização)\n",
        "x = layers.Dropout(rate = 0.2)(x)                  \n",
        "# adicionando uma camada de saída com um neurônio e uma função de ativação sigmoide\n",
        "x = layers.Dense(units = 12, activation = tf.nn.softmax)(x)           \n",
        "\n",
        "# conecatando as camadas definidas acima com a arquitetura inception\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "# compilando a rede \n",
        "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.0001), loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc']) "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMrO-fi62SW"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.0.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbbzuySD62xG"
      },
      "source": [
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwaUi23Z659p",
        "outputId": "35c8114e-3fd7-4f0d-bcfd-a581a58803bc"
      },
      "source": [
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 10, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 2.7430 - acc: 0.1297 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 3276s 15s/step - loss: 2.7415 - acc: 0.1299 - val_loss: 2.0415 - val_acc: 0.3653\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.36529, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.0.hdf5\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 2.1434 - acc: 0.2205WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 829s 4s/step - loss: 2.1433 - acc: 0.2205 - val_loss: 2.1219 - val_acc: 0.3082\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.36529\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 2.0100 - acc: 0.2427WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 835s 4s/step - loss: 2.0099 - acc: 0.2427 - val_loss: 2.1330 - val_acc: 0.2843\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.36529\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.8726 - acc: 0.2531WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 812s 4s/step - loss: 1.8726 - acc: 0.2531 - val_loss: 1.9666 - val_acc: 0.3272\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.36529\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.7124 - acc: 0.2681WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 816s 4s/step - loss: 1.7126 - acc: 0.2680 - val_loss: 1.9610 - val_acc: 0.3033\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.36529\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.6286 - acc: 0.2786WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 818s 4s/step - loss: 1.6286 - acc: 0.2786 - val_loss: 1.8762 - val_acc: 0.3381\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.36529\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.4967 - acc: 0.3110WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 828s 4s/step - loss: 1.4967 - acc: 0.3110 - val_loss: 2.0402 - val_acc: 0.2285\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.36529\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.3755 - acc: 0.3121WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 831s 4s/step - loss: 1.3756 - acc: 0.3121 - val_loss: 1.8196 - val_acc: 0.3445\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.36529\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.2934 - acc: 0.3338WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 823s 4s/step - loss: 1.2934 - acc: 0.3338 - val_loss: 1.8466 - val_acc: 0.3674\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.36529 to 0.36742, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.0.hdf5\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.1697 - acc: 0.3556WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 818s 4s/step - loss: 1.1698 - acc: 0.3555 - val_loss: 2.0186 - val_acc: 0.2294\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.36742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XneEhH7GTQoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e06f418-bd10-4c27-b9d9-19daae71f50c"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.1.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "\n",
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 5, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.1111 - acc: 0.3664WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 814s 4s/step - loss: 1.1111 - acc: 0.3664 - val_loss: 1.9059 - val_acc: 0.3035\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.30350, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.1.hdf5\n",
            "Epoch 2/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.0349 - acc: 0.3793WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 836s 4s/step - loss: 1.0349 - acc: 0.3793 - val_loss: 1.9440 - val_acc: 0.2675\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.30350\n",
            "Epoch 3/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.9617 - acc: 0.3941WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 819s 4s/step - loss: 0.9617 - acc: 0.3941 - val_loss: 2.0016 - val_acc: 0.2720\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.30350\n",
            "Epoch 4/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.8898 - acc: 0.4141WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 815s 4s/step - loss: 0.8898 - acc: 0.4141 - val_loss: 1.9563 - val_acc: 0.3021\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.30350\n",
            "Epoch 5/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.8357 - acc: 0.4347WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 826s 4s/step - loss: 0.8357 - acc: 0.4347 - val_loss: 2.0416 - val_acc: 0.2630\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.30350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiZVR-uejlGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d8b2f1-6615-4a38-986b-08e5026a36b0"
      },
      "source": [
        "# testando a capacidade de generalização do modelo com os dados de teste\n",
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 1004s 50s/step - loss: 2.0524 - acc: 0.2644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0524284839630127, 0.2643939256668091]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4plp2vLoAek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e85f0b-947e-4bb6-fbe9-ab34fed80d08"
      },
      "source": [
        "# salvando o modelo previamente treinado\n",
        "model.save('/content/drive/MyDrive/weights-nih/inception/modelv1.1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/modelv1.1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cyPZfxrCQxY"
      },
      "source": [
        "### Continuação do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeZRgi03CU_W"
      },
      "source": [
        "# carregando o modelo salvo\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/weights-nih/inception/modelv1.1')\n",
        "# carregando os pesos previamente treinados\n",
        "model.load_weights('/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.1.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igDjqQX8CphX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460a7f72-ed7d-4afc-8a48-8061fec29429"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "\n",
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 15, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 1.0955 - acc: 0.3774 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 2849s 13s/step - loss: 1.0953 - acc: 0.3774 - val_loss: 1.8447 - val_acc: 0.3288\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.32884, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\n",
            "Epoch 2/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.9383 - acc: 0.4069WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 807s 4s/step - loss: 0.9383 - acc: 0.4069 - val_loss: 2.0493 - val_acc: 0.2263\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.32884\n",
            "Epoch 3/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.8828 - acc: 0.4115WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 808s 4s/step - loss: 0.8828 - acc: 0.4115 - val_loss: 2.0454 - val_acc: 0.2659\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.32884\n",
            "Epoch 4/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.8227 - acc: 0.4388WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 809s 4s/step - loss: 0.8227 - acc: 0.4388 - val_loss: 2.0092 - val_acc: 0.2652\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.32884\n",
            "Epoch 5/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.7770 - acc: 0.4449WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 809s 4s/step - loss: 0.7770 - acc: 0.4449 - val_loss: 1.7527 - val_acc: 0.3887\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.32884 to 0.38873, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\n",
            "Epoch 6/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.7067 - acc: 0.4704WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 824s 4s/step - loss: 0.7068 - acc: 0.4704 - val_loss: 1.8752 - val_acc: 0.3473\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.38873\n",
            "Epoch 7/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.6692 - acc: 0.4821WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 826s 4s/step - loss: 0.6693 - acc: 0.4821 - val_loss: 2.0638 - val_acc: 0.2557\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.38873\n",
            "Epoch 8/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.6224 - acc: 0.5010WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 822s 4s/step - loss: 0.6225 - acc: 0.5010 - val_loss: 2.0059 - val_acc: 0.3158\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.38873\n",
            "Epoch 9/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.6151 - acc: 0.5146WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 827s 4s/step - loss: 0.6151 - acc: 0.5146 - val_loss: 2.0164 - val_acc: 0.2834\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.38873\n",
            "Epoch 10/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.5692 - acc: 0.5298WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 827s 4s/step - loss: 0.5692 - acc: 0.5297 - val_loss: 1.8752 - val_acc: 0.3629\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.38873\n",
            "Epoch 11/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.5263 - acc: 0.5439WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 853s 4s/step - loss: 0.5264 - acc: 0.5439 - val_loss: 2.0161 - val_acc: 0.3234\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.38873\n",
            "Epoch 12/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4899 - acc: 0.5566WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 831s 4s/step - loss: 0.4899 - acc: 0.5566 - val_loss: 1.8214 - val_acc: 0.3918\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.38873 to 0.39181, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\n",
            "Epoch 13/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.5739WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 814s 4s/step - loss: 0.4746 - acc: 0.5739 - val_loss: 1.8521 - val_acc: 0.4022\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.39181 to 0.40223, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\n",
            "Epoch 14/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4474 - acc: 0.5810WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 826s 4s/step - loss: 0.4474 - acc: 0.5810 - val_loss: 1.7120 - val_acc: 0.4732\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.40223 to 0.47325, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.2.hdf5\n",
            "Epoch 15/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4249 - acc: 0.5966WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 837s 4s/step - loss: 0.4249 - acc: 0.5966 - val_loss: 2.0630 - val_acc: 0.3563\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.47325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Ky2Egz94DK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e705e7-b249-4703-f16a-9c95151ca411"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "\n",
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 15, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4228 - acc: 0.6002WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 833s 4s/step - loss: 0.4228 - acc: 0.6002 - val_loss: 1.8684 - val_acc: 0.4439\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.44389, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5\n",
            "Epoch 2/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.4082 - acc: 0.6139WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 821s 4s/step - loss: 0.4082 - acc: 0.6139 - val_loss: 1.8236 - val_acc: 0.4276\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.44389\n",
            "Epoch 3/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3880 - acc: 0.6218WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 821s 4s/step - loss: 0.3880 - acc: 0.6218 - val_loss: 1.9466 - val_acc: 0.3800\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.44389\n",
            "Epoch 4/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3703 - acc: 0.6345WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 840s 4s/step - loss: 0.3703 - acc: 0.6345 - val_loss: 1.9207 - val_acc: 0.4309\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.44389\n",
            "Epoch 5/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3522 - acc: 0.6475WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 844s 4s/step - loss: 0.3522 - acc: 0.6475 - val_loss: 2.1126 - val_acc: 0.3277\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.44389\n",
            "Epoch 6/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3354 - acc: 0.6587WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 830s 4s/step - loss: 0.3354 - acc: 0.6587 - val_loss: 2.0578 - val_acc: 0.3767\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.44389\n",
            "Epoch 7/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3266 - acc: 0.6652WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 824s 4s/step - loss: 0.3266 - acc: 0.6652 - val_loss: 1.9434 - val_acc: 0.4167\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.44389\n",
            "Epoch 8/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3169 - acc: 0.6759WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 826s 4s/step - loss: 0.3169 - acc: 0.6759 - val_loss: 2.0411 - val_acc: 0.4993\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.44389 to 0.49929, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5\n",
            "Epoch 9/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3004 - acc: 0.6842WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 828s 4s/step - loss: 0.3004 - acc: 0.6842 - val_loss: 1.8617 - val_acc: 0.4875\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.49929\n",
            "Epoch 10/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2934 - acc: 0.6962WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 827s 4s/step - loss: 0.2934 - acc: 0.6962 - val_loss: 1.8985 - val_acc: 0.5059\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.49929 to 0.50592, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5\n",
            "Epoch 11/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2796 - acc: 0.7016WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 824s 4s/step - loss: 0.2796 - acc: 0.7016 - val_loss: 1.9810 - val_acc: 0.4510\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.50592\n",
            "Epoch 12/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2728 - acc: 0.7086WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 825s 4s/step - loss: 0.2728 - acc: 0.7086 - val_loss: 2.0003 - val_acc: 0.4600\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.50592\n",
            "Epoch 13/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2625 - acc: 0.7201WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 845s 4s/step - loss: 0.2625 - acc: 0.7201 - val_loss: 1.9181 - val_acc: 0.5218\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.50592 to 0.52178, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5\n",
            "Epoch 14/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2567 - acc: 0.7224WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 828s 4s/step - loss: 0.2567 - acc: 0.7224 - val_loss: 2.4921 - val_acc: 0.3449\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.52178\n",
            "Epoch 15/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2552 - acc: 0.7301WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 818s 4s/step - loss: 0.2552 - acc: 0.7301 - val_loss: 2.1740 - val_acc: 0.4067\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.52178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec56ZiKpuVPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea873da-da90-4c62-9674-0c42a8e7ed11"
      },
      "source": [
        "# salvando o modelo previamente treinado\n",
        "model.save('/content/drive/MyDrive/weights-nih/inception/modelv1.3')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/modelv1.3/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp5MKGPYubQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d656b77-4f29-40d2-901e-602bc0f6e4eb"
      },
      "source": [
        "# testando a capacidade de predição do modelo com dados de teste\n",
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 1068s 53s/step - loss: 2.1838 - acc: 0.3973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1838455200195312, 0.3973484933376312]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR9qn0Pfm2w5"
      },
      "source": [
        "### Continuação da etapa de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiTplvLkm6y6"
      },
      "source": [
        "# carrregando os pesos previamente treinados\n",
        "model.load_weights('/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.3.hdf5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z75YBmcKnCpS",
        "outputId": "62c4609c-d809-454f-a6cb-50bfa0fad180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
        "\n",
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 15, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 8)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.3025 - acc: 0.7144 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 3761s 18s/step - loss: 0.3023 - acc: 0.7144 - val_loss: 1.9189 - val_acc: 0.4964\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.49645, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 2/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2439 - acc: 0.7395WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1395s 7s/step - loss: 0.2439 - acc: 0.7395 - val_loss: 1.9972 - val_acc: 0.5028\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.49645 to 0.50284, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 3/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2286 - acc: 0.7448WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1414s 7s/step - loss: 0.2287 - acc: 0.7448 - val_loss: 2.0850 - val_acc: 0.4512\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.50284\n",
            "Epoch 4/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2229 - acc: 0.7470WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 653s 3s/step - loss: 0.2229 - acc: 0.7470 - val_loss: 2.2165 - val_acc: 0.4744\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.50284\n",
            "Epoch 5/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2215 - acc: 0.7635WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 634s 3s/step - loss: 0.2215 - acc: 0.7634 - val_loss: 2.0185 - val_acc: 0.4853\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.50284\n",
            "Epoch 6/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2107 - acc: 0.7629WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 632s 3s/step - loss: 0.2107 - acc: 0.7629 - val_loss: 2.3231 - val_acc: 0.4295\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.50284\n",
            "Epoch 7/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.2115 - acc: 0.7633WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 635s 3s/step - loss: 0.2115 - acc: 0.7633 - val_loss: 2.0004 - val_acc: 0.5040\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.50284 to 0.50402, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 8/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1970 - acc: 0.7797WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1345s 6s/step - loss: 0.1970 - acc: 0.7797 - val_loss: 2.0532 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.50402 to 0.51989, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 9/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1991 - acc: 0.7818WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1390s 7s/step - loss: 0.1991 - acc: 0.7818 - val_loss: 2.1790 - val_acc: 0.4676\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.51989\n",
            "Epoch 10/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1870 - acc: 0.7899WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 664s 3s/step - loss: 0.1871 - acc: 0.7899 - val_loss: 2.5495 - val_acc: 0.4266\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.51989\n",
            "Epoch 11/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1894 - acc: 0.7882WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 642s 3s/step - loss: 0.1895 - acc: 0.7882 - val_loss: 2.2745 - val_acc: 0.4704\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.51989\n",
            "Epoch 12/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1861 - acc: 0.7935WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 641s 3s/step - loss: 0.1861 - acc: 0.7935 - val_loss: 2.3085 - val_acc: 0.4967\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.51989\n",
            "Epoch 13/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1796 - acc: 0.8045WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 643s 3s/step - loss: 0.1796 - acc: 0.8045 - val_loss: 2.1478 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.51989 to 0.52462, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 14/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1773 - acc: 0.8053WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1254s 6s/step - loss: 0.1774 - acc: 0.8053 - val_loss: 2.1928 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.52462 to 0.53741, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n",
            "Epoch 15/15\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - ETA: 0s - loss: 0.1756 - acc: 0.8075WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "208/208 [==============================] - 1307s 6s/step - loss: 0.1756 - acc: 0.8075 - val_loss: 2.2122 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.53741 to 0.56818, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_v1.4.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upsyl7KnrzVj",
        "outputId": "24738298-20fe-4510-d8c7-8b64c369b9cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# salvando o modelo previamente treinado\n",
        "model.save('/content/drive/MyDrive/weights-nih/inception/modelv1.4')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/modelv1.4/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}