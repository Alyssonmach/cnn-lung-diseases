{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lltg8Aim2eBk"
   },
   "source": [
    "# Experimento 6\n",
    "***\n",
    "- Rede Inception\n",
    "- Conjunto de Dados: NIH\n",
    "- Analisando o treinamento para detecção de anormalidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGc_sJwE2v7L"
   },
   "source": [
    "### Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2VNdgNJh2nu_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBlFN3uN250P"
   },
   "source": [
    "### Importação dos dados\n",
    "***\n",
    "- Todo o dataset foi pré-processado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J8L6EUve227_"
   },
   "outputs": [],
   "source": [
    "# importando os dataframes dos dados de treinamento, validação e teste\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/train_df.csv', sep = ',', index_col=  0)\n",
    "validation_df = pd.read_csv('/content/drive/MyDrive/validation_df.csv', sep = ',', index_col=  0)\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/test_df.csv' , sep = ',', index_col=  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IqKuqHF4DUa1"
   },
   "outputs": [],
   "source": [
    "# tornando as classes na coluna 'labels' categórica\n",
    "train_df.loc[train_df.labels == 1, 'labels'] = 'abnormal'\n",
    "train_df.loc[train_df.labels == 0, 'labels'] = 'normal'\n",
    "\n",
    "validation_df.loc[validation_df.labels == 1, 'labels'] = 'abnormal'\n",
    "validation_df.loc[validation_df.labels == 0, 'labels'] = 'normal'\n",
    "\n",
    "test_df.loc[test_df.labels == 1, 'labels'] = 'abnormal'\n",
    "test_df.loc[test_df.labels == 0, 'labels'] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VK3FCgkiiRer"
   },
   "outputs": [],
   "source": [
    "# ajustando a quantidade de exemplos nos dados de treinamento relativo a radiográficas normais\n",
    "train_normal_cases = train_df[train_df.labels == 'normal']\n",
    "train_abnormal_cases = train_df[train_df.labels == 'abnormal']\n",
    "train_normal_cases, _ = train_test_split(train_normal_cases, test_size = 0.5, random_state = 42)\n",
    "train = np.concatenate((train_normal_cases, train_abnormal_cases))\n",
    "train_df = pd.DataFrame(train, columns = ['Image Index', 'finding_labels', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "a9uNHRrS4Uin",
    "outputId": "bf82996c-ee79-4541-a639-630a580f20a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>finding_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/images-nih4/images/0002...</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/images-nih3/images/0001...</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/MyDrive/images-nih2/images/0000...</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/MyDrive/images-nih2/images/0000...</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/MyDrive/images-nih2/images/0001...</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Image Index finding_labels  labels\n",
       "0  /content/drive/MyDrive/images-nih4/images/0002...     No Finding  normal\n",
       "1  /content/drive/MyDrive/images-nih3/images/0001...     No Finding  normal\n",
       "2  /content/drive/MyDrive/images-nih2/images/0000...     No Finding  normal\n",
       "3  /content/drive/MyDrive/images-nih2/images/0000...     No Finding  normal\n",
       "4  /content/drive/MyDrive/images-nih2/images/0001...     No Finding  normal"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizando como é a organização do dataframe pré-processado\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QGd53xcdiiY",
    "outputId": "b050e4c0-b085-47d6-a975-fedbdd378b6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal      27811\n",
       "abnormal    25452\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizando a quantidade de imagens disponíveis por classe\n",
    "train_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nIdbGooef88-"
   },
   "outputs": [],
   "source": [
    "# organizando um dicionário para realizar o balanceamento nos dados das classes\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_df['labels']),\n",
    "                                                  train_df['labels'])\n",
    "class_weight = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nikcd9Fj4tpv",
    "outputId": "4eb56cd6-37e9-4c82-8c34-4ca6e85ee4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53259 validated image filenames belonging to 2 classes.\n",
      "Found 4268 validated image filenames belonging to 2 classes.\n",
      "Found 2640 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
    "image_generator = ImageDataGenerator(rescale = 1./255., rotation_range = 10, zoom_range = 0.2)\n",
    "\n",
    "# criando o gerador de imagens de treinamento \n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "                                                      dataframe = train_df,\n",
    "                                                      x_col = 'Image Index',\n",
    "                                                      y_col = 'labels',\n",
    "                                                      batch_size = 256,\n",
    "                                                      seed = 42,\n",
    "                                                      shuffle = True,\n",
    "                                                      class_mode = 'categorical',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      target_size = (256, 256))\n",
    "\n",
    "# normalizando as imagens de teste \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "# criando o gerador de imagens de validação \n",
    "valid_generator = test_datagen.flow_from_dataframe(\n",
    "                                                    dataframe = validation_df,\n",
    "                                                    x_col = 'Image Index',\n",
    "                                                    y_col = 'labels',\n",
    "                                                    batch_size = 128,\n",
    "                                                    seed = 42,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    target_size = (256, 256))\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "                                                  dataframe = test_df, \n",
    "                                                  x_col = 'Image Index',\n",
    "                                                  y_col = 'labels',\n",
    "                                                  batch_size = 128,\n",
    "                                                  seed = 42,\n",
    "                                                  shuffle = True,\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s37H75lFDbZ_",
    "outputId": "e01f486d-7c7a-4b6c-b0f4-d656308c62ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abnormal': 0, 'normal': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizando a ordem numérica das classes nos dados de treinamento\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy6pLh4c5Gk4"
   },
   "source": [
    "### Preparando a rede neural convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tp0U2-Ut5Xvq",
    "outputId": "3c5387cc-0b25-47e7-9221-8cbdb77144e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-14 22:49:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 108.177.127.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  70.6MB/s    in 1.2s    \n",
      "\n",
      "2021-04-14 22:49:44 (70.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baixando os pesos treinados da rede inception\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZxH8IPA15bIi"
   },
   "outputs": [],
   "source": [
    "# referenciando o local em que os pesos estão armazenados\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# carregando a arquitetura inception pré-treinada\n",
    "pre_trained_model = InceptionV3(input_shape = (256, 256, 3), include_top = False, weights = None)\n",
    "\n",
    "# carregando os pesos treinados com outros dados \n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# definindo as flags iniciais  \n",
    "pre_trained_model.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "# para a arquitetura inception, a rede será retreinada a partir da camada 'mixed6'\n",
    "for layer in pre_trained_model.layers:\n",
    "    if layer.name == 'mixed6':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# obtendo a última camada como sendo a nomeada por 'mixed7'\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gXwzaXiT58Oi"
   },
   "outputs": [],
   "source": [
    "# definindo uma camada de achatamento\n",
    "x = layers.Flatten()(last_output)\n",
    "# conecatando a rede uma camada com 1024 neurônios e função de ativação relu\n",
    "x = layers.Dense(units = 1024, activation = tf.nn.relu)(x)     \n",
    "# conecatando a rede uma camada com 128 neurônios e função de ativação relu\n",
    "x = layers.Dense(units = 512, activation = tf.nn.relu)(x) \n",
    "# aplicando uma camada de dropout com uma taxa de 20% (normalização)\n",
    "x = layers.Dropout(rate = 0.2)(x)                 \n",
    "# adicionando uma camada de saída com um neurônio e uma função de ativação sigmoide\n",
    "x = layers.Dense  (units = 2, activation = tf.nn.softmax)(x)           \n",
    "\n",
    "# conecatando as camadas definidas acima com a arquitetura inception\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "# compilando a rede \n",
    "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.001), loss = 'categorical_crossentropy', \n",
    "              metrics = ['acc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VrMrO-fi62SW"
   },
   "outputs": [],
   "source": [
    "# definindo o caminho pelo qual os pesos serão armazenados \n",
    "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\"\n",
    "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbbzuySD62xG"
   },
   "outputs": [],
   "source": [
    "# definindo um array de callbacks\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwaUi23Z659p",
    "outputId": "e4b45402-1540-4003-ead8-9af9db9382fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 8.1826 - acc: 0.5508 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 3488s 16s/step - loss: 8.1542 - acc: 0.5510 - val_loss: 0.7319 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63755, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6402 - acc: 0.6450WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1476s 7s/step - loss: 0.6402 - acc: 0.6450 - val_loss: 0.6323 - val_acc: 0.6428\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63755 to 0.64276, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6254 - acc: 0.6554WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1338s 6s/step - loss: 0.6254 - acc: 0.6554 - val_loss: 0.7333 - val_acc: 0.5753\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.64276\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6219 - acc: 0.6595WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 672s 3s/step - loss: 0.6219 - acc: 0.6596 - val_loss: 0.6698 - val_acc: 0.5665\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.64276\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6118 - acc: 0.6680WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 650s 3s/step - loss: 0.6118 - acc: 0.6679 - val_loss: 0.6348 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64276 to 0.65246, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.6072 - acc: 0.6736WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1297s 6s/step - loss: 0.6072 - acc: 0.6736 - val_loss: 0.6204 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.65246 to 0.66098, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5972 - acc: 0.6796WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1355s 6s/step - loss: 0.5972 - acc: 0.6796 - val_loss: 0.6045 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.66098 to 0.66880, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5898 - acc: 0.6820WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1295s 6s/step - loss: 0.5898 - acc: 0.6820 - val_loss: 0.6150 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.66880 to 0.67898, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5804 - acc: 0.6877WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1449s 7s/step - loss: 0.5804 - acc: 0.6877 - val_loss: 0.7130 - val_acc: 0.6236\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.67898\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5689 - acc: 0.7009WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 676s 3s/step - loss: 0.5689 - acc: 0.7009 - val_loss: 0.6013 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.67898 to 0.70218, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.0.hdf5\n"
     ]
    }
   ],
   "source": [
    "# treinando a rede neural convolucional\n",
    "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
    "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
    "                              callbacks = callbacks, epochs = 10, class_weight = class_weight,\n",
    "                              use_multiprocessing = True, workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rDqbuUqksHb",
    "outputId": "f24b1518-f1dd-4f78-88fe-801c849da192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1831s 91s/step - loss: 0.6030 - acc: 0.6920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6029810309410095, 0.6920454502105713]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avaliando a capacidade de predição do modelo com os dados de teste\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjQudMoWohfi",
    "outputId": "f354a117-e5e4-49a2-ee35-b6b914ff4c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/model_binv1.0/assets\n"
     ]
    }
   ],
   "source": [
    "# salvando o modelo treinado\n",
    "model.save('/content/drive/MyDrive/weights-nih/inception/model_binv1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-DCFpQfBjEA"
   },
   "source": [
    "### Continuação do Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsaI8KuZl6Mv"
   },
   "outputs": [],
   "source": [
    "# carregando o modelo salvo\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/weights-nih/inception/model_binv1.0')\n",
    "# carregando os pesos treinados com o modelo\n",
    "model.load_weights('/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpDaKu_-BXWw",
    "outputId": "4f16e303-a420-4553-eca5-793054e50fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5440 - acc: 0.7187 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 4115s 19s/step - loss: 0.5440 - acc: 0.7188 - val_loss: 0.6753 - val_acc: 0.6851\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68513, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.1.hdf5\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5186 - acc: 0.7355WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1472s 7s/step - loss: 0.5186 - acc: 0.7355 - val_loss: 0.7348 - val_acc: 0.6586\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.68513\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.5147 - acc: 0.7366WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 655s 3s/step - loss: 0.5147 - acc: 0.7366 - val_loss: 0.7393 - val_acc: 0.6402\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.68513\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4995 - acc: 0.7488WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 637s 3s/step - loss: 0.4995 - acc: 0.7488 - val_loss: 0.6674 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.68513\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4960 - acc: 0.7496WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 639s 3s/step - loss: 0.4961 - acc: 0.7496 - val_loss: 0.8488 - val_acc: 0.6229\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.68513\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4834 - acc: 0.7550WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 643s 3s/step - loss: 0.4835 - acc: 0.7550 - val_loss: 0.7308 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.68513\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4758 - acc: 0.7648WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 644s 3s/step - loss: 0.4759 - acc: 0.7647 - val_loss: 0.6800 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.68513 to 0.69200, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.1.hdf5\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4718 - acc: 0.7663WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1268s 6s/step - loss: 0.4718 - acc: 0.7663 - val_loss: 0.7143 - val_acc: 0.6735\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69200\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4679 - acc: 0.7671WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 657s 3s/step - loss: 0.4679 - acc: 0.7671 - val_loss: 1.0405 - val_acc: 0.5888\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69200\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.7696WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 637s 3s/step - loss: 0.4631 - acc: 0.7696 - val_loss: 0.7430 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69200\n"
     ]
    }
   ],
   "source": [
    "# definindo o caminho pelo qual os pesos serão armazenados \n",
    "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.1.hdf5\"\n",
    "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "# definindo um array de callbacks\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# treinando a rede neural convolucional\n",
    "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
    "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
    "                              callbacks = callbacks, epochs = 10, class_weight = class_weight,\n",
    "                              use_multiprocessing = True, workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oVfjGOWhcvx",
    "outputId": "5fd91aec-6976-4d28-d2b7-639e591cd263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4556 - acc: 0.7737WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 639s 3s/step - loss: 0.4556 - acc: 0.7737 - val_loss: 0.8387 - val_acc: 0.6357\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63565, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4487 - acc: 0.7789WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1196s 6s/step - loss: 0.4487 - acc: 0.7789 - val_loss: 0.7741 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63565 to 0.65696, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4426 - acc: 0.7836WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1266s 6s/step - loss: 0.4426 - acc: 0.7836 - val_loss: 0.7241 - val_acc: 0.6593\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.65696 to 0.65933, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4355 - acc: 0.7874WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1315s 6s/step - loss: 0.4355 - acc: 0.7874 - val_loss: 0.8637 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.65933\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4313 - acc: 0.7908WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 647s 3s/step - loss: 0.4313 - acc: 0.7908 - val_loss: 0.7963 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65933\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4196 - acc: 0.7984WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 633s 3s/step - loss: 0.4196 - acc: 0.7984 - val_loss: 0.9202 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65933\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4167 - acc: 0.8001WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 635s 3s/step - loss: 0.4167 - acc: 0.8001 - val_loss: 0.7944 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65933 to 0.68134, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4113 - acc: 0.7997WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 1228s 6s/step - loss: 0.4113 - acc: 0.7997 - val_loss: 0.8708 - val_acc: 0.6357\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.68134\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4060 - acc: 0.8064WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 650s 3s/step - loss: 0.4060 - acc: 0.8064 - val_loss: 0.8891 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.68134\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3954 - acc: 0.8114WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 637s 3s/step - loss: 0.3954 - acc: 0.8114 - val_loss: 0.8653 - val_acc: 0.6321\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.68134\n"
     ]
    }
   ],
   "source": [
    "# definindo o caminho pelo qual os pesos serão armazenados \n",
    "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5\"\n",
    "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "# definindo um array de callbacks\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# treinando a rede neural convolucional\n",
    "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
    "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
    "                              callbacks = callbacks, epochs = 10, class_weight = class_weight,\n",
    "                              use_multiprocessing = True, workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOSw-5jwurg_",
    "outputId": "a680df3e-d4d9-4480-b241-3f51e03cf7ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/model_binv1.2/assets\n"
     ]
    }
   ],
   "source": [
    "# salvando o modelo treinado\n",
    "model.save('/content/drive/MyDrive/weights-nih/inception/model_binv1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB81BDRxus6M",
    "outputId": "5b1142c7-0b17-44ef-b2ce-cd8d8d132130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1845s 92s/step - loss: 0.8507 - acc: 0.6443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.850670576095581, 0.644318163394928]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando a capacidade de predição do modelo com os dados de teste\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiqWm8B2gQyf"
   },
   "source": [
    "### Continuação da etapa de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bq7puxKUgKLQ"
   },
   "outputs": [],
   "source": [
    "# carregando os pesos previamente treinados\n",
    "model.load_weights('/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8ufmRHPgYUd",
    "outputId": "dc509ad9-6705-4773-efae-ac91e6ca62b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.4354 - acc: 0.7957 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 5856s 28s/step - loss: 0.4353 - acc: 0.7957 - val_loss: 0.8334 - val_acc: 0.6366\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63660, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.3.hdf5\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3980 - acc: 0.8113 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 2721s 13s/step - loss: 0.3980 - acc: 0.8113 - val_loss: 0.8280 - val_acc: 0.6480\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63660 to 0.64796, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.3.hdf5\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3886 - acc: 0.8174WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 2014s 10s/step - loss: 0.3886 - acc: 0.8174 - val_loss: 0.9707 - val_acc: 0.6354\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.64796\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3840 - acc: 0.8200WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 741s 3s/step - loss: 0.3840 - acc: 0.8200 - val_loss: 0.9529 - val_acc: 0.6070\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.64796\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3930 - acc: 0.8120WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 717s 3s/step - loss: 0.3930 - acc: 0.8120 - val_loss: 0.8481 - val_acc: 0.6487\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64796 to 0.64867, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.3.hdf5\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3816 - acc: 0.8210WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 2044s 10s/step - loss: 0.3816 - acc: 0.8210 - val_loss: 0.8538 - val_acc: 0.6373\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.64867\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3757 - acc: 0.8241WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 802s 4s/step - loss: 0.3757 - acc: 0.8241 - val_loss: 0.8361 - val_acc: 0.6624\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.64867 to 0.66241, saving model to /content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.3.hdf5\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3708 - acc: 0.8266WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 2247s 11s/step - loss: 0.3708 - acc: 0.8266 - val_loss: 0.8282 - val_acc: 0.6428\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.66241\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3625 - acc: 0.8302WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 777s 4s/step - loss: 0.3626 - acc: 0.8302 - val_loss: 1.2351 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.66241\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - ETA: 0s - loss: 0.3634 - acc: 0.8316WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "208/208 [==============================] - 744s 3s/step - loss: 0.3634 - acc: 0.8316 - val_loss: 1.0270 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.66241\n"
     ]
    }
   ],
   "source": [
    "# definindo o caminho pelo qual os pesos serão armazenados \n",
    "filepath = \"/content/drive/MyDrive/weights-nih/inception/transferlearning_weights_bin_v1.3.hdf5\"\n",
    "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "# definindo um array de callbacks\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# treinando a rede neural convolucional\n",
    "history = model.fit_generator(train_generator, steps_per_epoch = 53263 // 256, \n",
    "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
    "                              callbacks = callbacks, epochs = 10, class_weight = class_weight,\n",
    "                              use_multiprocessing = True, workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qjxJ8jms8LC",
    "outputId": "fe8493d1-a5e9-4f61-fe8d-6103ad741773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/weights-nih/inception/model_binv1.3/assets\n"
     ]
    }
   ],
   "source": [
    "# salvando o modelo treinado\n",
    "model.save('/content/drive/MyDrive/weights-nih/inception/model_binv1.3')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "experiment5_dataset_nih.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
