{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment5-dataset-nih-v2.0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNNWgMgIwN67Wq9W1Srh68V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230MFUN7-q3r"
      },
      "source": [
        "# Experimento 5 \n",
        "***\n",
        "- Rede ResNet\n",
        "- Conjunto de dados NIH\n",
        "- Analisando o treinamento de uma rede com multiclassificadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxMda8jx_DMh"
      },
      "source": [
        "### Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2zr7-3h_C2L"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from keras.applications.resnet import ResNet152\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgfyHGw5_amB"
      },
      "source": [
        "### Importação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6i6mNkR-nJV"
      },
      "source": [
        "# importando os dataframes dos dados de treinamento, validação e teste\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/train_df.csv', sep = ',', index_col=  0)\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/validation_df.csv', sep = ',', index_col=  0)\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/test_df.csv' , sep = ',', index_col=  0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lPfg0ASO_sXB",
        "outputId": "4e1dde32-7ed7-4521-a215-d6c719d810af"
      },
      "source": [
        "# visualizando como é a organização do dataframe pré-processado\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>finding_labels</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87745</th>\n",
              "      <td>/content/drive/MyDrive/images-nih1/images/0000...</td>\n",
              "      <td>Consolidation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82970</th>\n",
              "      <td>/content/drive/MyDrive/images-nih1/images/0000...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51704</th>\n",
              "      <td>/content/drive/MyDrive/images-nih3/images/0001...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38340</th>\n",
              "      <td>/content/drive/MyDrive/images-nih3/images/0001...</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71153</th>\n",
              "      <td>/content/drive/MyDrive/images-nih4/images/0002...</td>\n",
              "      <td>Infiltration</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Image Index finding_labels  labels\n",
              "87745  /content/drive/MyDrive/images-nih1/images/0000...  Consolidation       1\n",
              "82970  /content/drive/MyDrive/images-nih1/images/0000...     No Finding       0\n",
              "51704  /content/drive/MyDrive/images-nih3/images/0001...     No Finding       0\n",
              "38340  /content/drive/MyDrive/images-nih3/images/0001...     No Finding       0\n",
              "71153  /content/drive/MyDrive/images-nih4/images/0002...   Infiltration       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDMmUv4qokQB",
        "outputId": "e87e5a7d-118e-4ebf-df57-e6db1d8c3764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de imagens disponíveis por classe\n",
        "train_df['finding_labels'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No Finding            55622\n",
              "Infiltration           8770\n",
              "Atelectasis            3902\n",
              "Effusion               3645\n",
              "Nodule                 2497\n",
              "Pneumothorax           2024\n",
              "Consolidation          1224\n",
              "Pleural_Thickening     1028\n",
              "Emphysema               818\n",
              "Fibrosis                671\n",
              "Edema                   578\n",
              "Pneumonia               295\n",
              "Name: finding_labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmc61_6I_1Qx"
      },
      "source": [
        "# organizando o balanceamento das classes\n",
        "total_train_examples = 55622 + 8770 + 3902 + 3645 + 2497 + 2024 + 1224 + 1028 + 818 + 671 + 578 + 295\n",
        "class_weight = {0: total_train_examples / 55622,\n",
        "                1: total_train_examples / 8770,\n",
        "                2: total_train_examples / 3902,\n",
        "                3: total_train_examples / 3645,\n",
        "                4: total_train_examples / 2497,\n",
        "                5: total_train_examples / 2024,\n",
        "                6: total_train_examples / 1224,\n",
        "                7: total_train_examples / 1028,\n",
        "                8: total_train_examples / 818,\n",
        "                9: total_train_examples / 671,\n",
        "                10: total_train_examples / 578,\n",
        "                11: total_train_examples / 295}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kUYb8f_5la",
        "outputId": "b55e6f0d-d255-4176-b00b-4ad6b607c51d"
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(rescale = 1./255., rotation_range = 10, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 256,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = test_datagen.flow_from_dataframe(\n",
        "                                                    dataframe = validation_df,\n",
        "                                                    x_col = 'Image Index',\n",
        "                                                    y_col = 'finding_labels',\n",
        "                                                    batch_size = 128,\n",
        "                                                    seed = 42,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (256, 256))\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  x_col = 'Image Index',\n",
        "                                                  y_col = 'finding_labels',\n",
        "                                                  batch_size = 128,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  target_size = (256, 256))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 81074 validated image filenames belonging to 12 classes.\n",
            "Found 4268 validated image filenames belonging to 12 classes.\n",
            "Found 2640 validated image filenames belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hudb3CJ2_8_0"
      },
      "source": [
        "### Preparando a rede neural convolucional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn5WcQTg_8Ls"
      },
      "source": [
        "# realizando a transferência de aprendizagem com a rede ResNet\n",
        "base_model = ResNet152(input_shape = (256, 256, 3), weights = 'imagenet', include_top = False)\n",
        "\n",
        "# pegando a última camada da DenseNet\n",
        "x = base_model.output\n",
        "# adicionando uma camada de Global Average Pooling\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "# adicionando uma camada densa com 512 neurônios\n",
        "x = layers.Dense(units = 512, activation = tf.nn.relu)(x)     \n",
        "# conecatando a rede uma camada com 128 neurônios e função de ativação relu\n",
        "x = layers.Dense(units = 256, activation = tf.nn.relu)(x) \n",
        "# aplicando uma camada de dropout com uma taxa de 20% (normalização)\n",
        "x = layers.Dropout(rate = 0.2)(x)\n",
        "# adicionando a camada de saída da rede \n",
        "predictions = layers.Dense(units = 12, activation = tf.nn.softmax)(x)\n",
        "\n",
        "# concatenando a rede importada com a rede definida (ajuste fino)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lJIAAcnATvK"
      },
      "source": [
        "# definindo as flags iniciais  \n",
        "model.trainable = True\n",
        "set_trainable = False\n",
        "\n",
        "# para a arquitetura DenseNet, a rede será retreinada a partir da camada 'conv5_block1_1_conv'\n",
        "for layer in model.layers:\n",
        "    if layer.name == 'conv5_block1_1_conv':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JYOVWDKDWHD"
      },
      "source": [
        "# compilando a rede \n",
        "model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.0001), loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnNYzSBSDb2S"
      },
      "source": [
        "# definindo o caminho pelo qual os pesos serão armazenados \n",
        "filepath = \"/content/drive/MyDrive/weights-nih/resnet/transferlearning_weights_v2.0.hdf5\"\n",
        "# callback para salvar o melhor valor dos pesos em relação ao desempenho com os dados de validação \n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, \n",
        "                             mode = 'max')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niww0CGtDufC"
      },
      "source": [
        "# definindo um array de callbacks\n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ZOITCvD0GW",
        "outputId": "b03208ec-09c0-4d30-9d2a-d7cfccf1399e"
      },
      "source": [
        "# treinando a rede neural convolucional\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = 81072 // 256, \n",
        "                              validation_data = valid_generator, validation_steps = 4268 // 128,\n",
        "                              callbacks = callbacks, epochs = 1, class_weight = class_weight,\n",
        "                              use_multiprocessing = True, workers = 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            " 24/316 [=>............................] - ETA: 1:16:58 - loss: 112.7497 - acc: 0.5704"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}