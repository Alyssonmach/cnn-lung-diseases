{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "4-dataset-nih.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arabic-appraisal"
      },
      "source": [
        "# Conjunto de Dados 4: *ChestXray-NIH*\n",
        "***\n",
        "> Disponível em: <https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345>. Acesso em 19 fev. 2021."
      ],
      "id": "arabic-appraisal"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stuffed-chinese"
      },
      "source": [
        "### Importação dos pacotes necessários"
      ],
      "id": "stuffed-chinese"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brilliant-oxide"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import urllib.request\n",
        "path = 'https://raw.githubusercontent.com/Alyssonmach/cnn-lung-diseases/main/assets/cxr8_dados.py'\n",
        "file_path = 'cxr8_dados.py'\n",
        "urllib.request.urlretrieve(path, file_path)\n",
        "from cxr8_dados import data_download, organize_csv, download_images, train_validation_test_split \n",
        "import glob\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "brilliant-oxide",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toxic-ballot"
      },
      "source": [
        "### Baixando os dados"
      ],
      "id": "toxic-ballot"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flexible-argentina"
      },
      "source": [
        "# baixando dataframe\n",
        "data_download('https://raw.githubusercontent.com/Alyssonmach/cnn-lung-diseases/main/assets/dataframe-info.csv', 'dataframe-info.csv')"
      ],
      "id": "flexible-argentina",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "northern-round"
      },
      "source": [
        "# baixando as imagens a serem utilizadas\n",
        "download_images()"
      ],
      "id": "northern-round",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heard-nightmare"
      },
      "source": [
        "# especificando o diretório com as imagens \n",
        "IMAGE_DIR = ['/content/drive/MyDrive/images-nih1',\n",
        "             '/content/drive/MyDrive/images-nih2',\n",
        "             '/content/drive/MyDrive/images-nih3',\n",
        "             '/content/drive/MyDrive/images-nih4']"
      ],
      "id": "heard-nightmare",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "digital-upper"
      },
      "source": [
        "# obtendo o dataframe organizando\n",
        "dataframe, (normal, anormal) = organize_csv('/content/dataframe-info.csv')"
      ],
      "id": "digital-upper",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq4fZfSS96XR",
        "outputId": "0bd89f62-6747-4eb3-e3ed-e6c5e1a934b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de dados disponíveis em cada classe\n",
        "dataframe['finding_labels'].value_counts()"
      ],
      "id": "Yq4fZfSS96XR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No Finding            60361\n",
              "Infiltration           9547\n",
              "Atelectasis            4215\n",
              "Effusion               3955\n",
              "Nodule                 2705\n",
              "Pneumothorax           2194\n",
              "Consolidation          1310\n",
              "Pleural_Thickening     1126\n",
              "Emphysema               892\n",
              "Fibrosis                727\n",
              "Edema                   628\n",
              "Pneumonia               322\n",
              "Name: finding_labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "molecular-trick",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b804d1b2-e6d2-40d2-9c0e-35607437a335"
      },
      "source": [
        "# visualizando o dataframe\n",
        "print(dataframe.head())\n",
        "print('dataframe shape:', dataframe.shape)"
      ],
      "id": "molecular-trick",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Image Index  finding_labels  labels\n",
            "0  00011895_001.png               0       0\n",
            "1  00015384_004.png               0       0\n",
            "2  00028131_011.png               0       0\n",
            "3  00028792_001.png               1       1\n",
            "4  00010716_000.png               0       0\n",
            "dataframe shape: (87982, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "regulation-parker"
      },
      "source": [
        "# particionando o dataset em dados de treino, validação e teste  \n",
        "train_df, validation_df, test_df = train_validation_test_split(dataframe)"
      ],
      "id": "regulation-parker",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "informational-rhythm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617d8093-eb45-4ef2-af15-99469b209d55"
      },
      "source": [
        "# visualizando detalhes dos dados de treinamento\n",
        "print(train_df.head())\n",
        "print('train_df shape:', train_df.shape)"
      ],
      "id": "informational-rhythm",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Image Index  finding_labels  labels\n",
            "87745  00000322_011.png               6       1\n",
            "82970  00006022_004.png               0       0\n",
            "51704  00019766_008.png               0       0\n",
            "38340  00017206_000.png               0       0\n",
            "71153  00026810_041.png               1       1\n",
            "train_df shape: (81074, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prospective-mailing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81d4898-d339-419d-a645-fd7cfb0a60b2"
      },
      "source": [
        "# visualizando detalhes dos dados de treinamento\n",
        "print(validation_df.head())\n",
        "print('validation_df shape:', validation_df.shape)"
      ],
      "id": "prospective-mailing",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Image Index  finding_labels  labels\n",
            "5623   00011667_001.png               0       0\n",
            "63643  00009988_001.png               0       0\n",
            "67737  00002664_000.png               0       0\n",
            "76165  00011606_006.png               3       1\n",
            "55740  00016719_016.png               6       1\n",
            "validation_df shape: (4268, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applied-progress",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc11acc5-78f2-466a-ee83-ac86c44a4904"
      },
      "source": [
        "# visualizando detalhes dos dados de teste \n",
        "print(test_df.head())\n",
        "print('validation_df shape:', test_df.shape)"
      ],
      "id": "applied-progress",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Image Index  finding_labels  labels\n",
            "42532  00019214_000.png               0       0\n",
            "5432   00011827_004.png               0       0\n",
            "30045  00012485_001.png               0       0\n",
            "10278  00025340_002.png               0       0\n",
            "40900  00023741_000.png               0       0\n",
            "validation_df shape: (2640, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absolute-rogers"
      },
      "source": [
        "### Gerados de Dados para a rede pelo Tensorflow"
      ],
      "id": "absolute-rogers"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "curSC-HwT-61"
      },
      "source": [
        "# função para baixar os caminhos de todas as imagens\n",
        "def find_files():\n",
        "\n",
        "  file1 = glob.glob('/content/drive/MyDrive/images-nih1/images/*.png')\n",
        "  time.sleep(10)\n",
        "  file2 = glob.glob('/content/drive/MyDrive/images-nih2/images/*.png')\n",
        "  time.sleep(10)\n",
        "  file3 = glob.glob('/content/drive/MyDrive/images-nih3/images/*.png')\n",
        "  time.sleep(10)\n",
        "  file4 = glob.glob('/content/drive/MyDrive/images-nih4/images/*.png')\n",
        "\n",
        "  return file1, file2, file3, file4\n",
        "\n",
        "file1, file2, file3, file4 = find_files()\n",
        "\n",
        "# função para adicionar os caminhos das imagens nos diretórios a partir do arquivo csv\n",
        "def replace_file(dataframe, new_file, image):\n",
        "\n",
        "  index = int(dataframe[dataframe['Image Index'] == image].index.values)\n",
        "  dataframe['Image Index'][index] = new_file\n",
        "\n",
        "  return None"
      ],
      "id": "curSC-HwT-61",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqIS1xsxNuaa"
      },
      "source": [
        "# organizando o arquivo csv \n",
        "\n",
        "result = ''\n",
        "\n",
        "for image in train_df['Image Index']:\n",
        "  for file_ in file1:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = train_df, new_file = file_, image = image)\n",
        "  for file_ in file2:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = train_df, new_file = file_, image = image)\n",
        "  for file_ in file3:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = train_df, new_file = file_, image = image)\n",
        "  for file_ in file4:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = train_df, new_file = file_, image = image)\n",
        "\n",
        "for image in validation_df['Image Index']:\n",
        "  for file_ in file1:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = validation_df, new_file = file_, image = image)\n",
        "  for file_ in file2:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = validation_df, new_file = file_, image = image)\n",
        "  for file_ in file3:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = validation_df, new_file = file_, image = image)\n",
        "  for file_ in file4:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = validation_df, new_file = file_, image = image)\n",
        "\n",
        "for image in test_df['Image Index']:\n",
        "  for file_ in file1:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = test_df, new_file = file_, image = image)\n",
        "  for file_ in file2:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = test_df, new_file = file_, image = image)\n",
        "  for file_ in file3:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = test_df, new_file = file_, image = image)\n",
        "  for file_ in file4:\n",
        "    result = file_.find(image)\n",
        "    if result > 0:\n",
        "      replace_file(dataframe = test_df, new_file = file_, image = image)\n"
      ],
      "id": "XqIS1xsxNuaa",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04gBKWqghiFv"
      },
      "source": [
        "# salvando os dataframes manipulados em arquivos csv\n",
        "train_df.to_csv('train_df.csv')\n",
        "validation_df.to_csv('validation_df.csv')\n",
        "test_df.to_csv('test_df.csv')"
      ],
      "id": "04gBKWqghiFv",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Rt1JV0gXWJ"
      },
      "source": [
        "# dicionário com o balancemanto de pesos das classes\n",
        "class_weights = {0: 3902, 1: 1224, 2: 578, 3: 3645, 4: 818, 5: 671,\n",
        "                 6: 8770, 7: 55622, 8: 2497, 9: 1028, 10: 295, 11: 2024}"
      ],
      "id": "a-Rt1JV0gXWJ",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dietary-sarah"
      },
      "source": [
        "> **Opção 1**"
      ],
      "id": "dietary-sarah"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smaller-rescue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc919859-199a-4a58-a76d-32603ae91e7d"
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True,\n",
        "                                     rotation_range = 10, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 256,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df, \n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 128,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  x_col = 'Image Index',\n",
        "                                                  y_col = 'finding_labels',\n",
        "                                                  batch_size = 128,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  color_mode = 'rgb',\n",
        "                                                  target_size = (256, 256))"
      ],
      "id": "smaller-rescue",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 81074 validated image filenames belonging to 12 classes.\n",
            "Found 4268 validated image filenames belonging to 12 classes.\n",
            "Found 2640 validated image filenames belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vulnerable-breach"
      },
      "source": [
        "- **Opção 2**"
      ],
      "id": "vulnerable-breach"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medical-assurance",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bad5ac3-1114-4cd8-e2ab-0c8596f96701"
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(rescale = 1./255., rotation_range = 10, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 256,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df,\n",
        "                                                      x_col = 'Image Index',\n",
        "                                                      y_col = 'finding_labels',\n",
        "                                                      batch_size = 128,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'categorical',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  x_col = 'Image Index',\n",
        "                                                  y_col = 'finding_labels',\n",
        "                                                  batch_size = 128,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  target_size = (256, 256))"
      ],
      "id": "medical-assurance",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 81074 validated image filenames belonging to 12 classes.\n",
            "Found 4268 validated image filenames belonging to 12 classes.\n",
            "Found 2640 validated image filenames belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYy4TDFh6SR",
        "outputId": "e5edb8ea-3cd1-4a04-fb15-9ee21ce686e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# observando os índices das classes encontradas\n",
        "train_generator.class_indices"
      ],
      "id": "pSYy4TDFh6SR",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Atelectasis': 0,\n",
              " 'Consolidation': 1,\n",
              " 'Edema': 2,\n",
              " 'Effusion': 3,\n",
              " 'Emphysema': 4,\n",
              " 'Fibrosis': 5,\n",
              " 'Infiltration': 6,\n",
              " 'No Finding': 7,\n",
              " 'Nodule': 8,\n",
              " 'Pleural_Thickening': 9,\n",
              " 'Pneumonia': 10,\n",
              " 'Pneumothorax': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    }
  ]
}