{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14418508-3512-4bb4-82a2-6f9ea01db20d",
   "metadata": {},
   "source": [
    "# Conjunto de Dados 1: _Montgomery County X-ray Set_\n",
    "***\n",
    "> Disponível em: <https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities>. Acesso em 19 fev. 2021.\n",
    "***\n",
    "# Conjunto de Dados 2: _China Set - The Shenzhen set - Chest X-ray Database_\n",
    "***\n",
    "> Disponível em: <https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities>. Acesso em 19 fev. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94328021-8618-4f6c-b5f9-52d88ee30726",
   "metadata": {},
   "source": [
    "### Importação dos pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955c0a57-3593-4375-bbce-4c6ec574b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a485b65-90ca-454d-8e0f-88c0ddbbacab",
   "metadata": {},
   "source": [
    "### Pré-processando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cae0752-2fd2-452f-881d-685d7c5a44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coletando o caminho dos arquivos dos dados do hospital shenzen\n",
    "filelist_shenzen = glob.glob('../0-datasets/montgomery-shenzen/arquivos-descompactados/ChinaSet_AllFiles/ChinaSet_AllFiles/CXR_png/*.png')\n",
    "# coletando o caminho dos arquivos dos dados do hospital montgomery\n",
    "filelist_montgomery = glob.glob('../0-datasets/montgomery-shenzen/arquivos-descompactados/Montgomery/MontgomerySet/CXR_png/*.png')\n",
    "# juntando os dois datasets\n",
    "filelist = filelist_shenzen + filelist_montgomery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd836e34-3d5b-4fdc-b313-711ec874a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de imagens: 800\n"
     ]
    }
   ],
   "source": [
    "# quantidade de imagens disponíveis no dataset\n",
    "print('quantidade de imagens:', str(len(filelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea59ff78-18b4-4454-bb21-b4e05fc8f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(file_list):\n",
    "    \n",
    "    # inicializando uma lista vazia\n",
    "    labels = []\n",
    "    \n",
    "    # iterando na lista de arquivos\n",
    "    for file in tqdm(file_list):\n",
    "        # detectando as classes presentes no nome da imagem\n",
    "        current_label = re.findall('[0-9]{4}_(.+?).png', file)\n",
    "        # adicionando a lista de rótulos as classes correspondentes a cada uma das imagens\n",
    "        if current_label[0] == '0':\n",
    "          labels.append('normal')\n",
    "        else:\n",
    "          labels.append('abnormal')\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a44890c-460c-4a69-a973-57cf08d2121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 114735.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# extraindo os rótulos\n",
    "labels = extract_label(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2539ad9-03fd-41da-a105-a061a9c6c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de rótulos: 800\n"
     ]
    }
   ],
   "source": [
    "# visualizando a quantidade de rótulos\n",
    "print('quantidade de rótulos:', str(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b3dc8e-4683-484f-ba9c-0111abd2dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataframe com os caminhos das imagens\n",
    "full_data = pd.DataFrame(filelist, columns = ['filepath'])\n",
    "# adicionando os rótulos em cada imagem\n",
    "full_data['target'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e002f412-b161-4c27-91bf-76df2e13468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de treinamento e de teste\n",
    "train_df, test_df = train_test_split(full_data, stratify = full_data['target'],\n",
    "                                     test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc728b18-07ad-416b-8609-c0e109b22b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de validação dos dados de treinamento\n",
    "train_df, validation_df = train_test_split(train_df, stratify = train_df['target'],\n",
    "                                           test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee04b5a-3dc2-4271-a695-0f466339d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de imagens de treinamento: 512\n",
      "quantidade de rótulos de treinamento: 512\n",
      "quantidade de imagens de teste: 160\n",
      "quantidade de rótulos de teste: 160\n",
      "quantidade de imagens de validação: 128\n",
      "quantidade de rótulos de validação: 128\n"
     ]
    }
   ],
   "source": [
    "# visualizando a quantidade de dados\n",
    "print('quantidade de imagens de treinamento:', len(train_df['filepath']))\n",
    "print('quantidade de rótulos de treinamento:', len(train_df['target']))\n",
    "print('quantidade de imagens de teste:', len(test_df['filepath']))\n",
    "print('quantidade de rótulos de teste:', len(test_df['target']))\n",
    "print('quantidade de imagens de validação:', len(validation_df['filepath']))\n",
    "print('quantidade de rótulos de validação:', len(validation_df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94aa238-7f20-4f6b-8cec-d16b167619fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizando um dicionário para realizar o balanceamento nos dados das classes\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_df['target']),\n",
    "                                                  train_df['target'])\n",
    "class_weight = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9662bff7-2187-4c47-9c67-2bff42111d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando os dataframes manipulados em arquivos csv\n",
    "train_df.to_csv('train_df.csv')\n",
    "validation_df.to_csv('validation_df.csv')\n",
    "test_df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b12f0-453d-4bfb-a5b8-3b70179ba225",
   "metadata": {},
   "source": [
    "### Gerador de dados para a rede pelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e680c211-79a7-4b38-81bd-a5dc29e2eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 validated image filenames belonging to 2 classes.\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 160 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
    "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True,\n",
    "                                     rotation_range = 20, zoom_range = 0.2)\n",
    "\n",
    "# criando o gerador de imagens de treinamento \n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "                                                      dataframe = train_df,\n",
    "                                                      directory = '',\n",
    "                                                      x_col = 'filepath',\n",
    "                                                      y_col = 'target',\n",
    "                                                      batch_size = 32,\n",
    "                                                      seed = 42,\n",
    "                                                      shuffle = True,\n",
    "                                                      class_mode = 'categorical',\n",
    "                                                      target_size = (256, 256))\n",
    "# criando o gerador de imagens de validação \n",
    "valid_generator = image_generator.flow_from_dataframe(\n",
    "                                                      dataframe = validation_df,\n",
    "                                                      directory = '.', \n",
    "                                                      x_col = 'filepath',\n",
    "                                                      y_col = 'target',\n",
    "                                                      batch_size = 32,\n",
    "                                                      seed = 42,\n",
    "                                                      shuffle = True,\n",
    "                                                      class_mode = 'categorical',\n",
    "                                                      target_size = (256, 256))\n",
    "\n",
    "# normalizando as imagens de teste \n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "                                                  dataframe = test_df, \n",
    "                                                  directory = '.',\n",
    "                                                  x_col = 'filepath',\n",
    "                                                  y_col = 'target',\n",
    "                                                  batch_size = 32,\n",
    "                                                  seed = 42,\n",
    "                                                  shuffle = True,\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62f00168-afd9-4e10-b94b-8d15fbcf51d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abnormal': 0, 'normal': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observando os índices das classes encontradas pelo gerador de dados do keras\n",
    "train_generator.class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
