{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "1-datasets-1-2.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stable-former"
      },
      "source": [
        "# Conjunto de Dados 1: _Montgomery County X-ray Set_\n",
        "***\n",
        "> Disponível em: <https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities>. Acesso em19 fev. 2021."
      ],
      "id": "stable-former"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "developing-wilderness"
      },
      "source": [
        "# Conjunto de Dados 2: _China Set - The Shenzhen set - Chest X-ray Database_\n",
        "***\n",
        "> Disponível em: <https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities>. Acesso em19 fev. 2021."
      ],
      "id": "developing-wilderness"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spanish-cabinet"
      },
      "source": [
        "### Importação dos pacotes necessários"
      ],
      "id": "spanish-cabinet"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "copyrighted-quarter"
      },
      "source": [
        "import glob\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/Alyssonmach/histogram-equalization/main/histogram_equalization.py', 'histogram_equalization.py')\n",
        "from histogram_equalization import histogram_equalization\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "copyrighted-quarter",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "governing-sodium"
      },
      "source": [
        "### Baixando os dados"
      ],
      "id": "governing-sodium"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynamic-representative"
      },
      "source": [
        "# baixando o dataset \n",
        "#urllib.request.urlretrieve('https://storage.googleapis.com/kaggle-data-sets/15700/20797/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210212%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210212T011952Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=5eacca38e85ec1b1aa31998c47098bcb8c762b1e90130d80400d96c20f19baed9ff447d160c77e6eb84a3d7723707f5baf92638c3098dab7a03fec2c9a2ce0bbb3471952cf4e1d3fb74157e5e01894112200556b3ab8542251fb4dc68b893b6cbfe749da94056bf7ce46bb7867bd3629cfe2d424d24c0af8060571ef8afb948ee76a5b5d422828afb065a17feea77c6a53a4fdd554e102ccc7859beadc604f82c73e7650ac6f69dff488d3af32419c9e70703289e02e6d49dcb7595c4a1d9dd015afe52527f54d956dcfd57d6d85fac7f3a30df250bde1dffcefc6cfa0f43514ec4867c6aa6a4781accb537d10e24dc77d79a8dc2e4715f7589aab01c23e9b15', 'datasets.zip')"
      ],
      "id": "dynamic-representative",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maritime-fighter"
      },
      "source": [
        "# descompactando o dataset e removendo o arquivo compactado\n",
        "#!unzip datasets.zip\n",
        "#!rm /content/datasets.zip"
      ],
      "id": "maritime-fighter",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "authorized-particle"
      },
      "source": [
        "# coletando o caminho dos arquivos dos dados do hospital montgomery\n",
        "filelist_montgomery = glob.glob('/content/drive/MyDrive/Montgomery/MontgomerySet/CXR_png/*.png')\n",
        "# coletando o caminho dos arquivos dos dados do hospital shenzen\n",
        "filelist_shenzen = glob.glob('/content/drive/MyDrive/ChinaSet_AllFiles/ChinaSet_AllFiles/CXR_png/*.png')\n",
        "# unindo o caminho dos arquivos dos hospitais montgomery e shenzen\n",
        "filelist = filelist_montgomery + filelist_shenzen"
      ],
      "id": "authorized-particle",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fundamental-tackle",
        "outputId": "a10e13b1-49c0-49ab-de79-4a67e803145d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# quantidade de imagens disponíveis no dataset\n",
        "print('quantidade de imagens:', str(len(filelist)))"
      ],
      "id": "fundamental-tackle",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de imagens: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adverse-league"
      },
      "source": [
        "def extract_label(file_list):\n",
        "    \n",
        "    # inicializando uma lista vazia\n",
        "    labels = []\n",
        "    \n",
        "    # iterando na lista de arquivos\n",
        "    for file in tqdm(file_list):\n",
        "        # detectando as classes presentes no nome da imagem\n",
        "        current_label = re.findall('[0-9]{4}_(.+?).png', file)\n",
        "        # adicionando a lista de rótulos as classes correspondentes a cada uma das imagens\n",
        "        labels.append(current_label[0])\n",
        "        \n",
        "    return labels"
      ],
      "id": "adverse-league",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suited-airline",
        "outputId": "d9ab8643-6b6d-4c3b-92e6-aef16e1edf30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# extraindo os rótulos\n",
        "labels = extract_label(filelist)"
      ],
      "id": "suited-airline",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [00:00<00:00, 138357.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adapted-wages",
        "outputId": "cb014096-ea11-40a7-9cce-047b4ac4f02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de rótulos\n",
        "print('quantidade de rótulos:', str(len(labels)))"
      ],
      "id": "adapted-wages",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de rótulos: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "annoying-diagnosis"
      },
      "source": [
        "# criando um dataframe com os caminhos das imagens\n",
        "full_data = pd.DataFrame(filelist, columns = ['filepath'])\n",
        "# adicionando os rótulos em cada imagem\n",
        "full_data['target'] = labels"
      ],
      "id": "annoying-diagnosis",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "executive-statement"
      },
      "source": [
        "# modificando o formato dos dados para float32\n",
        "dict_type = {'target': 'float32'}\n",
        "full_data = full_data.astype(dict_type)"
      ],
      "id": "executive-statement",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coastal-macro"
      },
      "source": [
        "# separando os dados de treinamento e de teste\n",
        "train_df, test_df = train_test_split(full_data, stratify = full_data['target'],\n",
        "                                     test_size = 0.2, random_state = 42)"
      ],
      "id": "coastal-macro",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "former-throw"
      },
      "source": [
        "# separando os dados de validação dos dados de treinamento\n",
        "train_df, validation_df = train_test_split(train_df, stratify = train_df['target'],\n",
        "                                           test_size = 0.2, random_state = 42)"
      ],
      "id": "former-throw",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otherwise-selection",
        "outputId": "ff188c13-495a-4d0c-f202-00f13f8fbcd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# visualizando a quantidade de dados\n",
        "print('quantidade de imagens de treinamento:', len(train_df['filepath']))\n",
        "print('quantidade de rótulos de treinamento:', len(train_df['target']))\n",
        "print('quantidade de imagens de teste:', len(test_df['filepath']))\n",
        "print('quantidade de rótulos de teste:', len(test_df['target']))\n",
        "print('quantidade de imagens de validação:', len(validation_df['filepath']))\n",
        "print('quantidade de rótulos de validação:', len(validation_df['target']))"
      ],
      "id": "otherwise-selection",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de imagens de treinamento: 512\n",
            "quantidade de rótulos de treinamento: 512\n",
            "quantidade de imagens de teste: 160\n",
            "quantidade de rótulos de teste: 160\n",
            "quantidade de imagens de validação: 128\n",
            "quantidade de rótulos de validação: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cordless-acquisition"
      },
      "source": [
        "### Gerados de Dados para a rede pelo Tensorflow"
      ],
      "id": "cordless-acquisition"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automotive-shepherd"
      },
      "source": [
        "> **Opção 1**"
      ],
      "id": "automotive-shepherd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mental-boutique",
        "outputId": "19e84528-75fb-4e1d-acf1-3a0a146a4664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True,\n",
        "                                     rotation_range = 20, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      directory = '',\n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df,\n",
        "                                                      directory = '.', \n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  directory = '.',\n",
        "                                                  x_col = 'filepath',\n",
        "                                                  y_col = 'target',\n",
        "                                                  batch_size = 32,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'raw',\n",
        "                                                  target_size = (256, 256))"
      ],
      "id": "mental-boutique",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 512 validated image filenames.\n",
            "Found 128 validated image filenames.\n",
            "Found 160 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tutorial-sympathy"
      },
      "source": [
        "> **Opção 2**"
      ],
      "id": "tutorial-sympathy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sitting-calendar",
        "outputId": "5c73e592-7d41-4d72-9ab3-d9220948d049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(preprocessing_function = histogram_equalization,\n",
        "                                     rescale = 1./255., rotation_range = 20, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      directory = '',\n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df,\n",
        "                                                      directory = '.', \n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(preprocessing_function = histogram_equalization,\n",
        "                                  rescale = 1./255.)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  directory = '.',\n",
        "                                                  x_col = 'filepath',\n",
        "                                                  y_col = 'target',\n",
        "                                                  batch_size = 32,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'raw',\n",
        "                                                  target_size = (256, 256))"
      ],
      "id": "sitting-calendar",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 512 validated image filenames.\n",
            "Found 128 validated image filenames.\n",
            "Found 160 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "catholic-manner"
      },
      "source": [
        "> **Opção 3**"
      ],
      "id": "catholic-manner"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "handed-recall",
        "outputId": "051090b3-f14d-4095-ecbd-e52ab360c6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# normalizando as imagens de treinamento e aplicando aumento de dados\n",
        "image_generator = ImageDataGenerator(rescale = 1./255.,\n",
        "                                     rotation_range = 20, zoom_range = 0.2)\n",
        "\n",
        "# criando o gerador de imagens de treinamento \n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = train_df,\n",
        "                                                      directory = '',\n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      color_mode = 'rgb',\n",
        "                                                      target_size = (256, 256))\n",
        "# criando o gerador de imagens de validação \n",
        "valid_generator = image_generator.flow_from_dataframe(\n",
        "                                                      dataframe = validation_df,\n",
        "                                                      directory = '.', \n",
        "                                                      x_col = 'filepath',\n",
        "                                                      y_col = 'target',\n",
        "                                                      batch_size = 32,\n",
        "                                                      seed = 42,\n",
        "                                                      shuffle = True,\n",
        "                                                      class_mode = 'raw',\n",
        "                                                      target_size = (256, 256))\n",
        "\n",
        "# normalizando as imagens de teste \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "                                                  dataframe = test_df, \n",
        "                                                  directory = '.',\n",
        "                                                  x_col = 'filepath',\n",
        "                                                  y_col = 'target',\n",
        "                                                  batch_size = 32,\n",
        "                                                  seed = 42,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode = 'raw',\n",
        "                                                  target_size = (256, 256))"
      ],
      "id": "handed-recall",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 512 validated image filenames.\n",
            "Found 128 validated image filenames.\n",
            "Found 160 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}