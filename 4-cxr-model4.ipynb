{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "northern-maintenance",
   "metadata": {
    "id": "metropolitan-junior"
   },
   "source": [
    "# Classificação de imagens de raio-x (CXR8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-camel",
   "metadata": {
    "id": "portable-choice"
   },
   "source": [
    "## Importação dos pacotes\n",
    "***\n",
    "- `Importação dos pacotes para preparação de dados`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stable-hypothetical",
   "metadata": {
    "id": "complimentary-entity"
   },
   "outputs": [],
   "source": [
    "# == preparação dos dados == \n",
    "from cxr8_dados import data_download, organize_csv, download_images, train_validation_test_split \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# == definição do modelo ==\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# == verificação do modelo\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# ignorando avisos de pacotes desatualizados  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-clark",
   "metadata": {
    "id": "filled-wesley"
   },
   "source": [
    "## Preparação dos dados\n",
    "***\n",
    "- `Fazer o download do dataframe e das imagens de radiografia`;  \n",
    "- `Organizar o dataframe e definir um diretório com as imagens`;\n",
    "- `Particionar o dataframe em dados de treinamento, validação e teste`;\n",
    "- `Analisar a distrubuição dos dados em cada uma das partições`;\n",
    "- `Preparar um gerador de dados de treinamento, validação e teste a partir do dataframe`;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interpreted-christian",
   "metadata": {
    "id": "detected-industry"
   },
   "outputs": [],
   "source": [
    "# baixando dataframe\n",
    "data_download('https://raw.githubusercontent.com/Alyssonmach/cnn-lung-diseases/main/dataframe-info.csv', 'dataframe-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-prague",
   "metadata": {
    "id": "becoming-biology"
   },
   "outputs": [],
   "source": [
    "# baixando as imagens a serem utilizadas\n",
    "download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aging-bracket",
   "metadata": {
    "id": "separated-guide"
   },
   "outputs": [],
   "source": [
    "# descompactando os arquivos e removendo os arquivos compactados\n",
    "!tar -xvzf images_01.tar.gz -C /content/\n",
    "!rm /content/images_01.tar.gz \n",
    "!tar -xvzf images_02.tar.gz -C /content/\n",
    "!rm /content/images_02.tar.gz\n",
    "!tar -xvzf images_03.tar.gz -C /content/\n",
    "!rm /content/images_03.tar.gz\n",
    "!tar -xvzf images_04.tar.gz -C /content/\n",
    "!rm /content/images_04.tar.gz\n",
    "!tar -xvzf images_05.tar.gz -C /content/\n",
    "!rm /content/images_05.tar.gz\n",
    "!tar -xvzf images_06.tar.gz -C /content/\n",
    "!rm /content/images_06.tar.gz\n",
    "!tar -xvzf images_07.tar.gz -C /content/\n",
    "!rm /content/images_07.tar.gz\n",
    "!tar -xvzf images_08.tar.gz -C /content/\n",
    "!rm /content/images_08.tar.gz\n",
    "!tar -xvzf images_09.tar.gz -C /content/\n",
    "!rm /content/images_09.tar.gz\n",
    "!tar -xvzf images_10.tar.gz -C /content/\n",
    "!rm /content/images_10.tar.gz\n",
    "!tar -xvzf images_11.tar.gz -C /content/\n",
    "!rm /content/images_11.tar.gz\n",
    "!tar -xvzf images_12.tar.gz -C /content/\n",
    "!rm /content/images_12.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "handled-michael",
   "metadata": {
    "id": "hungry-circus"
   },
   "outputs": [],
   "source": [
    "# especificando o diretório com as imagens \n",
    "IMAGE_DIR = \"/content/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sustained-coaching",
   "metadata": {
    "id": "DN8ZeLZVUZpr"
   },
   "outputs": [],
   "source": [
    "# obtendo o dataframe organizando\r",
    " dataframe = organize_csv('/content/dataframe-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "romance-trigger",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "center-lexington",
    "outputId": "134f09b7-25da-4a96-aca4-671fd94d76c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Image Index  labels\n",
      "0  00003683_006.png       0\n",
      "1  00017620_002.png       0\n",
      "2  00016074_011.png       1\n",
      "3  00005218_003.png       1\n",
      "4  00022677_005.png       0\n",
      "dataframe shape: (48747, 2)\n"
     ]
    }
   ],
   "source": [
    "# visualizando o dataframe\n",
    "print(dataframe.head())\n",
    "print('dataframe shape:', dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unnecessary-notification",
   "metadata": {
    "id": "controlling-feeding"
   },
   "outputs": [],
   "source": [
    "# particionando o dataset em dados de treino, validação e teste  \n",
    "train_df, validation_df, test_df = train_validation_test_split(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "circular-birthday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYmqv_2tT11d",
    "outputId": "8cb0bcfc-efbc-433a-8596-f2d0f6387ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Image Index  labels\n",
      "2947   00019140_001.png       1\n",
      "29173  00005261_002.png       1\n",
      "42712  00001265_000.png       0\n",
      "25474  00013930_002.png       1\n",
      "4944   00022093_000.png       1\n",
      "train_df shape: (39484, 2)\n"
     ]
    }
   ],
   "source": [
    "# visualizando detalhes dos dados de treinamento\r\n",
    "print(train_df.head())\r\n",
    "print('train_df shape:', train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unusual-technology",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJXYhqpJ0mlL",
    "outputId": "4f8dab7a-047d-4608-feaa-9431d15b0caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Image Index  labels\n",
      "8289   00007474_000.png       0\n",
      "2044   00001829_000.png       0\n",
      "40923  00006605_010.png       1\n",
      "20813  00029801_003.png       1\n",
      "25273  00005140_002.png       0\n",
      "validation_df shape: (4388, 2)\n"
     ]
    }
   ],
   "source": [
    "# visualizando detalhes dos dados de treinamento\r\n",
    "print(validation_df.head())\r\n",
    "print('validation_df shape:', validation_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "following-keeping",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpPuJxxkrCw0",
    "outputId": "c9869317-4f3f-4b76-a2dd-d8dc5234a4cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Image Index  labels\n",
      "31843  00015071_000.png       1\n",
      "36040  00023933_000.png       0\n",
      "45886  00017225_005.png       1\n",
      "5326   00011460_037.png       1\n",
      "40405  00021586_000.png       1\n",
      "validation_df shape: (4875, 2)\n"
     ]
    }
   ],
   "source": [
    "# visualizando detalhes dos dados de teste \r\n",
    "print(test_df.head())\r\n",
    "print('validation_df shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "local-hanging",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1O_NXk5wQdA",
    "outputId": "14cf8593-716f-4261-bf4e-55eb354f1f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39484 validated image filenames.\n",
      "Found 4388 validated image filenames.\n",
      "Found 4875 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# normalizando as imagens de treinamento e aplicando aumento de dados\r\n",
    "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\r\n",
    "\r\n",
    "# criando o gerador de imagens de treinamento \r\n",
    "train_generator = image_generator.flow_from_dataframe(\r\n",
    "                                                      dataframe = train_df,\r\n",
    "                                                      directory = IMAGE_DIR,\r\n",
    "                                                      x_col = 'Image Index',\r\n",
    "                                                      y_col = 'labels',\r\n",
    "                                                      batch_size = 256,\r\n",
    "                                                      seed = 42,\r\n",
    "                                                      shuffle = True,\r\n",
    "                                                      class_mode = 'raw',\r\n",
    "                                                      color_mode = 'rgb',\r\n",
    "                                                      target_size = (256, 256))\r\n",
    "# criando o gerador de imagens de validação \r\n",
    "valid_generator = image_generator.flow_from_dataframe(\r\n",
    "                                                      dataframe = validation_df,\r\n",
    "                                                      directory = IMAGE_DIR, \r\n",
    "                                                      x_col = 'Image Index',\r\n",
    "                                                      y_col = 'labels',\r\n",
    "                                                      batch_size = 128,\r\n",
    "                                                      seed = 42,\r\n",
    "                                                      shuffle = True,\r\n",
    "                                                      class_mode = 'raw',\r\n",
    "                                                      target_size = (256, 256))\r\n",
    "\r\n",
    "# normalizando as imagens de teste \r\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True)\r\n",
    "\r\n",
    "test_generator = test_datagen.flow_from_dataframe(\r\n",
    "                                                  dataframe = test_df, \r\n",
    "                                                  directory = IMAGE_DIR,\r\n",
    "                                                  x_col = 'Image Index',\r\n",
    "                                                  y_col = 'labels',\r\n",
    "                                                  batch_size = 128,\r\n",
    "                                                  seed = 42,\r\n",
    "                                                  shuffle = True,\r\n",
    "                                                  class_mode = 'raw',\r\n",
    "                                                  target_size = (256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-surprise",
   "metadata": {
    "id": "brown-casting"
   },
   "source": [
    "## Definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "signed-spanish",
   "metadata": {
    "id": "digital-understanding"
   },
   "outputs": [],
   "source": [
    "# definindo o local do arquivo em que os pesos devem ser salvos \n",
    "filepath = \"transferlearning_weights.hdf5\" \n",
    "# definindo um callback de checkpoint para salvar os pesos durante o treinamento  \n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "separate-beginning",
   "metadata": {
    "id": "julian-engineering"
   },
   "outputs": [],
   "source": [
    "# definindo um callback de redução da taxa de aprendizado caso a rede entre em um platô  \n",
    "lr_reduce = ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, min_delta = 1e-5, patience = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "seasonal-single",
   "metadata": {
    "id": "preceding-lottery"
   },
   "outputs": [],
   "source": [
    "# definindo uma lista de callbacks\n",
    "callbacks = [checkpoint, lr_reduce] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lovely-village",
   "metadata": {
    "id": "removable-clone"
   },
   "outputs": [],
   "source": [
    "# transferência de aprendizado\n",
    "conv_base = VGG19(weights = 'imagenet', include_top = False, input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "unusual-yahoo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "romantic-fiber",
    "outputId": "bfb12fab-05ae-4409-b500-a26762ec8e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualizando o a arquitetura VGG19 utilizada \n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "likely-center",
   "metadata": {
    "id": "independent-liabilities"
   },
   "outputs": [],
   "source": [
    "# definindo inicialmente toda rede como treinável \n",
    "conv_base.trainable = True\n",
    "# criando uma flag \n",
    "set_trainable = False\n",
    "\n",
    "# iterando entre as camadas da rede convolucional VGG19 \n",
    "for layer in conv_base.layers:\n",
    "    # caso estiver na última camada... \n",
    "    if layer.name == 'block5_conv1':\n",
    "        # configure-a como treinável \n",
    "        set_trainable = True\n",
    "    \n",
    "    # caso a flag for verdadeira (na última camada)...\n",
    "    if set_trainable:\n",
    "        # mantenha a camada treinável \n",
    "        layer.trainable = True\n",
    "    # caso a flag seja falsa (demais camadas)... \n",
    "    else:\n",
    "        # mantenha as características aprendidas pelas camadas (não treináveis) \n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "exposed-beast",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stone-windows",
    "outputId": "53c06808-6d38-43b2-c552-d0e33a68ed70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# observando a arquitetura da rede após o refinamento\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "expired-turner",
   "metadata": {
    "id": "preliminary-found"
   },
   "outputs": [],
   "source": [
    "# definindo um modelo sequencial de rede neural \n",
    "model = models.Sequential()\n",
    "# adicionando toda a arquitetura da VGG19 após o refinamento \n",
    "model.add(conv_base)\n",
    "# adicionando uma camada de pooling (método do maior píxel) \n",
    "model.add(layers.MaxPooling2D())\n",
    "# aplicando uma camada de normalização para otimizar a rede \n",
    "model.add(layers.BatchNormalization())\n",
    "# aplicando uma camada de achatamento para conectar as camadas de convolução a uma rede neural densa \n",
    "model.add(layers.Flatten())\n",
    "# definindo uma camada densa com 128 neurônios e uma função de ativação relu\n",
    "model.add(layers.Dense(units = 128, activation = tf.nn.relu))\n",
    "# aplicando uma camada de normalização na rede neural densa (zera 20% dos neurônios da camada anterior)\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "# aplicando uma camada de saída com 15 unidades e uma função de ativação softmax \n",
    "model.add(layers.Dense(units = 2, activation = tf.nn.softmax)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "developing-influence",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "another-upset",
    "outputId": "402cc759-98a4-4480-fb27-d623b2549754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 8, 8, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 21,075,394\n",
      "Trainable params: 10,489,218\n",
      "Non-trainable params: 10,586,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualizando a nova arquitetura definida baseada em transferência de aprendizado\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "norwegian-spell",
   "metadata": {
    "id": "canadian-witch"
   },
   "outputs": [],
   "source": [
    "# compilando o modelo\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr = 5e-3), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-jersey",
   "metadata": {
    "id": "received-drink"
   },
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-meditation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7-MB7U8PmQ0",
    "outputId": "b153e7a2-a37b-41d5-b9ce-23dafa9130d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 26/154 [====>.........................] - ETA: 9:43:49 - loss: 2.7432 - acc: 0.5370"
     ]
    }
   ],
   "source": [
    "# treinando a rede \r\n",
    "history = model.fit_generator(train_generator,\r\n",
    "                              steps_per_epoch = 39484 // 256, \r\n",
    "                              validation_data = valid_generator,\r\n",
    "                              validation_steps = 4388 // 128,\r\n",
    "                              callbacks = callbacks, epochs = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-corporation",
   "metadata": {
    "id": "chronic-lambda"
   },
   "source": [
    "## Verificação do modelo"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CXR8-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
